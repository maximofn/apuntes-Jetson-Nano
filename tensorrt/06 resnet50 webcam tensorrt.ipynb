{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet50 on webcam - tensorrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximo.fernandez@AEROESPACIAL.SENER/miniconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import skimage.transform as skt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict with ImageNet labels\n",
    "with open('imagenet_labels.txt') as f:\n",
    "    labels = eval(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=1\n",
    "# BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50_pytorch_BS1.onnx file already exists\n"
     ]
    }
   ],
   "source": [
    "onnx_file = f\"resnet50_pytorch_BS{BATCH_SIZE}.onnx\"\n",
    "if not os.path.exists(onnx_file):\n",
    "    dummy_input=torch.randn(BATCH_SIZE, 3, 224, 224)\n",
    "    torch.onnx.export(model, dummy_input, f\"resnet50_pytorch_BS{BATCH_SIZE}.onnx\", verbose=False)\n",
    "else:\n",
    "    print(f\"{onnx_file} file already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export model to TRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_FP16 = True\n",
    "target_dtype = np.float16 if USE_FP16 else np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50_engine_pytorch_BS1.trt engine already exists\n"
     ]
    }
   ],
   "source": [
    "tensorrt_file = f\"resnet50_engine_pytorch_BS{BATCH_SIZE}.trt\"\n",
    "if not os.path.exists(tensorrt_file):\n",
    "    if USE_FP16:\n",
    "        !/usr/src/tensorrt/bin/trtexec --onnx=resnet50_pytorch_BS{BATCH_SIZE}.onnx --saveEngine=resnet50_engine_pytorch_BS{BATCH_SIZE}.trt  --explicitBatch --inputIOFormats=fp16:chw --outputIOFormats=fp16:chw --fp16\n",
    "    else:\n",
    "        !/usr/src/tensorrt/bin/trtexec --onnx=resnet50_pytorch_BS{BATCH_SIZE}.onnx --saveEngine=resnet50_engine_pytorch_BS{BATCH_SIZE}.trt  --explicitBatch\n",
    "else:\n",
    "    print(f\"{tensorrt_file} engine already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config cuda an TRT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(f\"resnet50_engine_pytorch_BS{BATCH_SIZE}.trt\", \"rb\")\n",
    "runtime = trt.Runtime(trt.Logger(trt.Logger.WARNING)) \n",
    "\n",
    "engine = runtime.deserialize_cuda_engine(f.read())\n",
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full HD resolution\n",
    "CAPTURE_WIDTH = 1920\n",
    "CAPTURE_HEIGHT = 1080\n",
    "resize = True\n",
    "if resize:\n",
    "    # 360p resolution\n",
    "    RESIZE_WIDTH = 360\n",
    "    RESIZE_HEIGHT = 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAPTURE_WIDTH)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAPTURE_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image shape: (720, 1280, 3), dtype: uint8\n",
      "Resized image shape: (360, 360, 3), dtype: float64\n",
      "Expanded image shape: (1, 360, 360, 3), dtype: float32\n",
      "Batched image shape: (1, 360, 360, 3)\n"
     ]
    }
   ],
   "source": [
    "ret, frame = cap.read()\n",
    "img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "print(f\"Original image shape: {img.shape}, dtype: {img.dtype}\")\n",
    "# resize = False\n",
    "if resize:\n",
    "    img = skt.resize(img, (RESIZE_WIDTH, RESIZE_HEIGHT))\n",
    "    print(f\"Resized image shape: {img.shape}, dtype: {img.dtype}\")\n",
    "else:\n",
    "    img = skt.resize(img, (CAPTURE_WIDTH, CAPTURE_HEIGHT))\n",
    "    print(f\"Resized image shape: {img.shape}, dtype: {img.dtype}\")\n",
    "img = np.expand_dims(np.array(img, dtype=np.float32), axis=0) # Expand image to have a batch dimension\n",
    "print(f\"Expanded image shape: {img.shape}, dtype: {img.dtype}\")\n",
    "input_batch = np.array(np.repeat(img, BATCH_SIZE, axis=0), dtype=np.float32) # Repeat across the batch dimension\n",
    "print(f\"Batched image shape: {input_batch.shape}\")\n",
    "# plt.imshow(input_batch[0].astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    norm = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    result = norm(torch.from_numpy(img).transpose(0,2).transpose(1,2))\n",
    "    result = np.array(result, dtype=np.float16)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to set input and output precisions to FP16 to fully enable it\n",
    "output = np.empty([BATCH_SIZE, 1000], dtype = target_dtype) \n",
    "\n",
    "# allocate device memory\n",
    "d_input = cuda.mem_alloc(1 * np.array(input_batch, dtype=np.float16).nbytes)\n",
    "d_output = cuda.mem_alloc(1 * output.nbytes)\n",
    "\n",
    "bindings = [int(d_input), int(d_output)]\n",
    "\n",
    "stream = cuda.Stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(batch): # result gets copied into output\n",
    "    # transfer input data to device\n",
    "    cuda.memcpy_htod_async(d_input, batch, stream)\n",
    "    # execute model\n",
    "    context.execute_async_v2(bindings, stream.handle, None)\n",
    "    # transfer predictions back\n",
    "    cuda.memcpy_dtoh_async(output, d_output, stream)\n",
    "    # syncronize threads\n",
    "    stream.synchronize()\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open webcam and start inference\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAPTURE_WIDTH)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAPTURE_HEIGHT)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 0.5\n",
    "fontColor = (10,10,10)\n",
    "lineThickness= 1\n",
    "lineType = cv2.LINE_AA\n",
    "pos = 30\n",
    "do_preprocess = True\n",
    "\n",
    "while True:\n",
    "    if 5 >= BATCH_SIZE:\n",
    "        ret, frame = cap.read()\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        if resize:\n",
    "            img = skt.resize(img, (RESIZE_WIDTH, RESIZE_HEIGHT))\n",
    "        else:\n",
    "            img = skt.resize(img, (CAPTURE_WIDTH, CAPTURE_HEIGHT))\n",
    "        img = np.expand_dims(np.array(img, dtype=np.float32), axis=0)\n",
    "    t0 = time.time()\n",
    "    ret, frame = cap.read()\n",
    "    t_frame = time.time()\n",
    "    pos = 30\n",
    "    cv2.putText(frame, f\"Image resolution: {frame.shape}\", (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "    pos += 20\n",
    "    cv2.putText(frame, f\"Open frame time: {((t_frame - t0)*1000):.2f} ms\", (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "    pos += 20\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    # Preprocess image\n",
    "    t1 = time.time()\n",
    "    img = frame.copy()\n",
    "    t_copy = time.time()\n",
    "    cv2.putText(frame, f\"Copy frame time: {((t_copy - t1)*1000):.2f} ms\", (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "    pos += 20\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    t_rgb = time.time()\n",
    "    cv2.putText(frame, f\"RGB conversion time: {((t_rgb - t_copy)*1000):.2f} ms\", (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "    pos += 20\n",
    "    if resize:\n",
    "        img = skt.resize(img, (RESIZE_HEIGHT, RESIZE_HEIGHT))\n",
    "    else:\n",
    "        img = skt.resize(img, (CAPTURE_WIDTH, CAPTURE_HEIGHT))\n",
    "    t_resize = time.time()\n",
    "    cv2.putText(frame, f\"Resize time: {((t_resize - t_rgb)*1000):.2f} ms\", (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "    pos += 20\n",
    "    img = np.expand_dims(np.array(img, dtype=np.float32), axis=0) # Expand image to have a batch dimension\n",
    "    t_expand = time.time()\n",
    "    cv2.putText(frame, f\"Expand time: {((t_expand - t_resize)*1000):.2f} ms\", (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "    pos += 20\n",
    "    if BATCH_SIZE > 1:\n",
    "        input_batch = np.array(np.repeat(img, BATCH_SIZE, axis=0), dtype=np.float32) # Repeat across the batch dimension\n",
    "        t_repeat = time.time()\n",
    "        cv2.putText(frame, f\"Repeat time: {((t_repeat - t_expand)*1000):.2f} ms\", (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "        pos += 20\n",
    "    else:\n",
    "        input_batch = img.copy()\n",
    "    if do_preprocess:\n",
    "        t_input = time.time()\n",
    "        preprocessed_image = np.array([preprocess_image(image) for image in input_batch])\n",
    "        t_preprocess = time.time()\n",
    "        cv2.putText(frame, f\"Preprocess time: {((t_preprocess - t_input)*1000):.2f} ms\", (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "        pos += 20\n",
    "        cv2.putText(frame, f\"preprocessed_image shape: {preprocessed_image.shape}\", (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "        pos += 20\n",
    "        cv2.putText(frame, f\"input_batch shape: {input_batch.shape}\", (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "        pos += 20\n",
    "    else:\n",
    "        preprocessed_image = input_batch[0].astype(np.float16)\n",
    "    t_total_preprocess = time.time()\n",
    "    cv2.putText(frame, f\"Total preprocess time: {((t_total_preprocess - t1)*1000):.2f} ms\", (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "    pos += 20\n",
    "\n",
    "    # Inference\n",
    "    start = time.time()\n",
    "    outputs = predict(preprocessed_image)\n",
    "    end = time.time()\n",
    "    cv2.putText(frame, f\"Inference time: {((end - start)*1000):.2f} ms\", (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "    pos += 20\n",
    "\n",
    "    # Postprocess\n",
    "    t2 = time.time()\n",
    "    idx = outputs[0].argmax()\n",
    "    t_postprocess = time.time()\n",
    "    cv2.putText(frame, f\"Predicted: {idx}-{labels[idx]}\", (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "    pos += 20\n",
    "    cv2.putText(frame, f\"Postprocess time: {((t_postprocess - t2)*1000):.2f} ms\", (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "    pos += 20\n",
    "\n",
    "    # FPS\n",
    "    T = time.time() - t0\n",
    "    cv2.putText(frame, f\"Total time: {(T*1000):.2f} ms\", (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "    pos += 20\n",
    "    cv2.putText(frame, f\"FPS: {1/T:.2f}\", (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "    pos += 20\n",
    "\n",
    "    # Display\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2af3135499c4cc4659220baa8d57d20fd35a58497fd7648737e38d0561042d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
