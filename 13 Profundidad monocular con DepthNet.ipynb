{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Profundidad monocular con DepthNet"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "La detección de profundidad es útil para tareas como mapeo, navegación y detección de obstáculos; sin embargo, históricamente requería una cámara estéreo o una cámara RGB-D. Ahora hay DNN que pueden inferir la profundidad relativa de una sola imagen monocular (también conocida como profundidad mono). Consulte el documento [FastDepth](https://arxiv.org/abs/1903.03273) del MIT para conocer uno de estos enfoques para lograr esto mediante el uso de redes totalmente convolucionales (FCN)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "![depthnet-0](https://raw.githubusercontent.com/dusty-nv/jetson-inference/dev/docs/images/depthnet-0.jpg)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "``depthNet`` acepta una imagen de un solo color como entrada y genera el mapa de profundidad. El mapa de profundidad está coloreado para su visualización, pero el campo de profundidad sin procesar también es accesible para acceder directamente a las profundidades. ``depthNet`` está disponible para su uso desde Python y C++ ."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uso de los programas precompilados de la Jetson"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí se pueden encontrar los códigos de los programas precompilados:\r\n",
        " * [C++](https://github.com/dusty-nv/jetson-inference/blob/master/examples/depthnet/depthnet.cpp)\r\n",
        " * [Python](https://github.com/dusty-nv/jetson-inference/blob/master/python/examples/depthnet.py)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelos de estimación de pose pre-entrenados disponibles"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, se muestran las redes de profundidad previamente entrenadas disponibles para descargar y el argumento ``--network`` asociado que ``depthNet`` utilizará para cargar los modelos previamente entrenados:\r\n",
        "\r\n",
        "|Model|CLI argument|NetworkType enum|\r\n",
        "|-------|----------|----------|\r\n",
        "|Monodepth-Mobilenet|``fcn-mobilenet``|``??``|\r\n",
        "|Monodepth-Resnet18|``fcn-resnet18``|``??``|\r\n",
        "|Monodepth-Resnet50|``fcn-resnet50``|``??``|"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uso de los programas precompilados de la Jetson"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Además de las rutas de entrada/salida, hay algunas opciones de línea de comandos adicionales:\r\n",
        "\r\n",
        " * flag ``--network`` (opcional) cambia el modelo de profundidad  que se está utilizando (el valor predeterminado es ``fcn-mobilenet``)\r\n",
        " * flag ``--visualize`` (opcional) acepta combinaciones separada por comas de ``input`` y ``depth`` (el valor predeterminado es ``input,depth``)\r\n",
        " * flag ``--depth-size`` (opcional) escala el tamaño del mapa de profundidad en relación con la entrada (el valor predeterminado es ``1.0``)\r\n",
        " * flag ``--filter-mode`` (opcional) establece el tipo de filtrado (``point`` o ``linear``) utilizado para el muestreo superior (el valor predeterminado es ``linear``)\r\n",
        " * flag ``--colormap`` (opcional) establece el mapeo de colores que se utilizará durante la visualización (el valor predeterminado es ``viridis_inverted``)\r\n",
        "\r\n",
        "Usar el flag ``--help`` para obtener más información"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ir a la carpeta con los programas precompilados con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ cd jetson-inference/build/aarch64/bin\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Procesamiento de una imagen"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, obtenemos la profundidad en una imagen de ejemplo con el programa precompilado ``depthNet``, tanto en C++ como en Python. Si está utilizando el contenedor Docker, es recomendable guardar la imagen de salida en el directorio images/test. Estas imágenes se podrán ver fácilmente desde su dispositivo host en el directorio jetson-inference/data/images/test.\r\n",
        "\r\n",
        "```\r\n",
        "# C++\r\n",
        "$ ./depthnet images/room_0.jpg images/test/depth_room_0.jpg\r\n",
        "\r\n",
        "# Python\r\n",
        "$ ./depthnet images/room_'.jpg images/test/depth_room_0.jpg\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Procesamiento de varias imágenes"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si queremos detectar varias imágenes\r\n",
        "\r\n",
        "```\r\n",
        "# C++\r\n",
        "$ ./depthnet \"images/room_*.jpg\" images/test/depth_room_%i.jpg\r\n",
        "\r\n",
        "# Python\r\n",
        "$ ./depthnet.py \"images/room_*.jpg\" images/test/depth_room_%i.jpg\r\n",
        "```\r\n",
        "\r\n",
        " > **nota**: cuando se usen asteriscos, hay que escribirlos siempre entre comillas (\"*.jpg\"). De lo contrario, el sistema operativo expandirá automáticamente la secuencia y modificará el orden de los argumentos en la línea de comandos, lo que puede resultar en que una de las imágenes de entrada sea sobrescrita por la salida."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Red"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si queremos cambiar el tipo de red flag `--network` (por defecto `fcn-mobilenet`)\r\n",
        "\r\n",
        "```\r\n",
        "# C++\r\n",
        "$ ./depthnet --network=fcn-mobilenet images/room_0.jpg images/test/depth_room_0.jpg  # fcn-mobilenet network\r\n",
        "$ ./depthnet --network=fcn-resnet18 images/room_0.jpg images/test/depth_room_0.jpg   # resnet18-hand network\r\n",
        "$ ./depthnet --network=fcn-resnet50 images/room_0.jpg images/test/depth_room_0.jpg   # resnet50-hand network\r\n",
        "\r\n",
        "# Python\r\n",
        "$ ./depthnet.py --network=fcn-mobilenet images/room_0.jpg images/test/depth_room_0.jpg  # fcn-mobilenet network\r\n",
        "$ ./depthnet.py --network=fcn-resnet18 images/room_0.jpg images/test/depth_room_0.jpg   # resnet18-hand network\r\n",
        "$ ./depthnet.py --network=fcn-resnet50 images/room_0.jpg images/test/depth_room_0.jpg   # resnet50-hand network\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualización"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede cambiar el modo de visualización es mediante el flag `--visualize`, se puede elegir ``input`` y ``depth`` (el valor predeterminado es ``input,depth``)\r\n",
        "\r\n",
        "```\r\n",
        "# C++\r\n",
        "$ ./depthnet --visualize=input images/room_0.jpg images/test/depth_room_0.jpg   # Visualize input\r\n",
        "$ ./depthnet --visualize=depth images/room_0.jpg images/test/depth_room_0.jpg   # Visualize depth\r\n",
        "\r\n",
        "# Python\r\n",
        "$ ./depthnet.py --visualize=input images/room_0.jpg images/test/depth_room_0.jpg   # Visualize input\r\n",
        "$ ./depthnet.py --visualize=depth images/room_0.jpg images/test/depth_room_0.jpg   # Visualize depth\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Escalado de la profundidad"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede cambiar el tamaño del mapa de profundidad en relación con la entrada mediante el flag `--depth-size` (el valor predeterminado es ``1.0``). Cuanto más pequeño el valor, más pequeño es el escalado\r\n",
        "\r\n",
        "```\r\n",
        "# C++\r\n",
        "$ ./depthnet --depth-size=1.0 images/room_0.jpg images/test/depth_room_0.jpg\r\n",
        "$ ./depthnet --depth-size=0.5 images/room_1.jpg images/test/depth_room_1.jpg\r\n",
        "$ ./depthnet --depth-size=2.0 images/room_2.jpg images/test/depth_room_2.jpg\r\n",
        "\r\n",
        "# Python\r\n",
        "$ ./depthnet.py --depth-size=1.0 images/room_0.jpg images/test/depth_room_0.jpg\r\n",
        "$ ./depthnet.py --depth-size=0.5 images/room_1.jpg images/test/depth_room_1.jpg\r\n",
        "$ ./depthnet.py --depth-size=2.0 images/room_2.jpg images/test/depth_room_2.jpg\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tipo de filtrado"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede cambiar el tipo de filtrado (``point`` o ``linear``) utilizado para el muestreo superior mediante el flag `--filter-mode` (el valor predeterminado es ``linear``). Cuanto más pequeño el valor, más pequeña es la linea\r\n",
        "\r\n",
        "```\r\n",
        "# C++\r\n",
        "$ ./depthnet --filter-mode=linear images/room_0.jpg images/test/depth_room_0.jpg\r\n",
        "$ ./depthnet --filter-mode=point images/room_1.jpg images/test/depth_room_1.jpg\r\n",
        "\r\n",
        "# Python\r\n",
        "$ ./depthnet.py --filter-mode=linear images/room_0.jpg images/test/depth_room_0.jpg\r\n",
        "$ ./depthnet.py --filter-mode=point images/room_1.jpg images/test/depth_room_1.jpg\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Colormap"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede cambiar el mapeo de colores que se utilizará durante la visualización mediante el flag `--colormap` (el valor predeterminado es ``viridis_inverted``)\r\n",
        "\r\n",
        "```\r\n",
        "# C++\r\n",
        "$ ./depthnet --colormap=viridis_inverted images/room_0.jpg images/test/depth_room_0.jpg\r\n",
        "\r\n",
        "# Python\r\n",
        "$ ./depthnet.py --colormap=viridis_inverted images/room_0.jpg images/test/depth_room_0.jpg\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Segmentación de vídeos"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si se quiere procesar un videdo solo hay que indicarlo en la entrada\r\n",
        "\r\n",
        "Para ello ejecutamos el docker montando la carpeta del SDK de VisionWorks\r\n",
        "\r\n",
        "```\r\n",
        "$ docker/run.sh --volume /usr/share/visionworks/sources/data:/videos\r\n",
        "```\r\n",
        "\r\n",
        "Y ya lo podemos procesar\r\n",
        "\r\n",
        "```\r\n",
        "# C++\r\n",
        "$ ./depthnet /videos/cars.mp4 images/test/cars_depth.mp4\r\n",
        "\r\n",
        "# Python\r\n",
        "$ ./depthnet.py /videos/cars.mp4 images/test/cars_depth.mp4\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crear un programa de clasificación en Python"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como vamos a crear un programa, lo primero que tenemos que hacer es crear una carpeta en el Host donde guardaremos el programa\r\n",
        "\r\n",
        "```\r\n",
        "$ cd ~/\r\n",
        "$ mkdir my-depth-python\r\n",
        "$ cd my-depth-python\r\n",
        "$ touch my-depth.py\r\n",
        "$ chmod +x my-depth.py\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación lo que hay que hacer es lanzar el Docker con una carpeta del Host compartida, para que así cuando se cierre el Docker no se borre el programa, para ello lanzamos el Docker con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ docker/run.sh --volume ~/my-depth-python:/my-depth-python   # mounted inside the container to /my-depth-python\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez dentro del Docker ir a la carpeta con los siguientes comandos\r\n",
        "\r\n",
        "```\r\n",
        "$ cd ../\r\n",
        "$ cd my-depth-python\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Editar el archivo .py con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ nano my-depth.py\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para crear un programa como el precompilado escribimos el siguiente código\r\n",
        "\r\n",
        "```Python\r\n",
        "import jetson.inference\r\n",
        "import jetson.utils\r\n",
        "\r\n",
        "import argparse\r\n",
        "import sys\r\n",
        "\r\n",
        "# Add /jetson-inference/python/examples path for import depthnet_utils\r\n",
        "sys.path.append('/jetson-inference/python/examples')\r\n",
        "from depthnet_utils import depthBuffers\r\n",
        "\r\n",
        "# parse the command line\r\n",
        "parser = argparse.ArgumentParser(description=\"Mono depth estimation on a video/image stream using depthNet DNN.\", \r\n",
        "                                 formatter_class=argparse.RawTextHelpFormatter, epilog=jetson.inference.depthNet.Usage() +\r\n",
        "                                 jetson.utils.videoSource.Usage() + jetson.utils.videoOutput.Usage() + jetson.utils.logUsage())\r\n",
        "\r\n",
        "parser.add_argument(\"input_URI\", type=str, default=\"\", nargs='?', help=\"URI of the input stream\")\r\n",
        "parser.add_argument(\"output_URI\", type=str, default=\"\", nargs='?', help=\"URI of the output stream\")\r\n",
        "parser.add_argument(\"--network\", type=str, default=\"fcn-mobilenet\", help=\"pre-trained model to load, see below for options\")\r\n",
        "parser.add_argument(\"--visualize\", type=str, default=\"input,depth\", help=\"visualization options (can be 'input' 'depth' 'input,depth'\")\r\n",
        "parser.add_argument(\"--depth-size\", type=float, default=1.0, help=\"scales the size of the depth map visualization, as a percentage of the input size (default is 1.0)\")\r\n",
        "parser.add_argument(\"--filter-mode\", type=str, default=\"linear\", choices=[\"point\", \"linear\"], help=\"filtering mode used during visualization, options are:\\n  'point' or 'linear' (default: 'linear')\")\r\n",
        "parser.add_argument(\"--colormap\", type=str, default=\"viridis-inverted\", help=\"colormap to use for visualization (default is 'viridis-inverted')\",\r\n",
        "                                  choices=[\"inferno\", \"inferno-inverted\", \"magma\", \"magma-inverted\", \"parula\", \"parula-inverted\", \r\n",
        "                                           \"plasma\", \"plasma-inverted\", \"turbo\", \"turbo-inverted\", \"viridis\", \"viridis-inverted\"])\r\n",
        "\r\n",
        "try:\r\n",
        "\topt = parser.parse_known_args()[0]\r\n",
        "except:\r\n",
        "\tprint(\"\")\r\n",
        "\tparser.print_help()\r\n",
        "\tsys.exit(0)\r\n",
        "\r\n",
        "# load the segmentation network\r\n",
        "net = jetson.inference.depthNet(opt.network, sys.argv)\r\n",
        "\r\n",
        "# create buffer manager\r\n",
        "buffers = depthBuffers(opt)\r\n",
        "\r\n",
        "# create video sources & outputs\r\n",
        "input = jetson.utils.videoSource(opt.input_URI, argv=sys.argv)\r\n",
        "output = jetson.utils.videoOutput(opt.output_URI, argv=sys.argv)\r\n",
        "\r\n",
        "# process frames until user exits\r\n",
        "while True:\r\n",
        "    # capture the next image\r\n",
        "    img_input = input.Capture()\r\n",
        "\r\n",
        "    # allocate buffers for this size image\r\n",
        "    buffers.Alloc(img_input.shape, img_input.format)\r\n",
        "\r\n",
        "    # process the mono depth and visualize\r\n",
        "    net.Process(img_input, buffers.depth, opt.colormap, opt.filter_mode)\r\n",
        "\r\n",
        "    # composite the images\r\n",
        "    if buffers.use_input:\r\n",
        "        jetson.utils.cudaOverlay(img_input, buffers.composite, 0, 0)\r\n",
        "        \r\n",
        "    if buffers.use_depth:\r\n",
        "        jetson.utils.cudaOverlay(buffers.depth, buffers.composite, img_input.width if buffers.use_input else 0, 0)\r\n",
        "\r\n",
        "    # render the output image\r\n",
        "    output.Render(buffers.composite)\r\n",
        "\r\n",
        "    # update the title bar\r\n",
        "    output.SetStatus(\"{:s} | {:s} | Network {:.0f} FPS\".format(opt.network, net.GetNetworkName(), net.GetNetworkFPS()))\r\n",
        "\r\n",
        "    # print out performance info\r\n",
        "    jetson.utils.cudaDeviceSynchronize()\r\n",
        "    net.PrintProfilerTimes()\r\n",
        "\r\n",
        "    # exit on input/output EOS\r\n",
        "    if not input.IsStreaming() or not output.IsStreaming():\r\n",
        "        break\r\n",
        "\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecutar el programa con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ python3 my-depth.py /dev/video0\r\n",
        "```\r\n",
        "\r\n",
        "En este caso abrirá la webcam, se pueden introducir las mismas variables que con el programa precompilado"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crear un programa ded clasificación en C++"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como vamos a crear un programa, lo primero que tenemos que hacer es crear una carpeta en el Host donde guardaremos el programa\r\n",
        "\r\n",
        "```\r\n",
        "$ cd ~/\r\n",
        "$ mkdir my-depth-cpp\r\n",
        "$ cd my-depth-cpp\r\n",
        "$ touch my-depth.cpp\r\n",
        "$ chmod +x my-depth.cpp\r\n",
        "$ touch CMakeLists.txt\r\n",
        "$ chmod +x CMakeLists.txt\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación lo que hay que hacer es lanzar el Docker con una carpeta del Host compartida, para que así cuando se cierre el Docker no se borre el programa, para ello lanzamos el Docker con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ docker/run.sh --volume ~/my-depth-cpp:/my-depth-cpp   # mounted inside the container to /my-depth-cpp\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez dentro del Docker ir a la carpeta con los siguientes comandos\r\n",
        "\r\n",
        "```\r\n",
        "$ cd ../\r\n",
        "$ cd my-depth-cpp\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Editar el archivo.cpp con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ nano my-depth.cpp\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para crear un programa como el precompilado escribimos el siguiente código\r\n",
        "\r\n",
        "```C++\r\n",
        "#include <jetson-utils/videoSource.h>\r\n",
        "#include <jetson-utils/videoOutput.h>\r\n",
        "\r\n",
        "#include <jetson-utils/cudaFont.h>\r\n",
        "#include <jetson-utils/cudaOverlay.h>\r\n",
        "#include <jetson-utils/cudaMappedMemory.h>\r\n",
        "\r\n",
        "#include <jetson-inference/depthNet.h>\r\n",
        "\r\n",
        "#include <signal.h>\r\n",
        "\r\n",
        "\r\n",
        "bool signal_recieved = false;\r\n",
        "\r\n",
        "void sig_handler(int signo)\r\n",
        "{\r\n",
        "\tif( signo == SIGINT )\r\n",
        "\t{\r\n",
        "\t\tprintf(\"received SIGINT\\n\");\r\n",
        "\t\tsignal_recieved = true;\r\n",
        "\t}\r\n",
        "}\r\n",
        "\r\n",
        "int usage()\r\n",
        "{\r\n",
        "\tprintf(\"usage: depthnet [--help] [--network NETWORK]\\n\");\r\n",
        "\tprintf(\"                [--colormap COLORMAP] [--filter-mode MODE]\\n\");\r\n",
        "\tprintf(\"                [--visualize VISUAL] [--depth-size SIZE]\\n\");\r\n",
        "\tprintf(\"                input_URI [output_URI]\\n\\n\");\r\n",
        "\tprintf(\"Mono depth estimation on a video/image stream using depthNet DNN.\\n\\n\");\r\n",
        "\tprintf(\"See below for additional arguments that may not be shown above.\\n\\n\");\r\n",
        "\tprintf(\"optional arguments:\\n\");\r\n",
        "\tprintf(\"  --help            show this help message and exit\\n\");\r\n",
        "\tprintf(\"  --network=NETWORK pre-trained model to load (see below for options)\\n\");\r\n",
        "\tprintf(\"  --visualize=VISUAL controls what is displayed (e.g. --visualize=input,depth)\\n\");\r\n",
        "\tprintf(\"                     valid combinations are:  'input', 'depth' (comma-separated)\\n\");\r\n",
        "\tprintf(\"  --depth-size=SIZE  scales the size of the depth map visualization, as a\\n\");\r\n",
        "\tprintf(\"                     percentage of the input size (default is 1.0)\\n\");\r\n",
        "\tprintf(\"  --filter-mode=MODE filtering mode used during visualization,\\n\");\r\n",
        "\tprintf(\"                     options are:  'point' or 'linear' (default: 'linear')\\n\");\r\n",
        "\tprintf(\"  --colormap=COLORMAP depth colormap (default is 'viridis-inverted')\\n\");\r\n",
        "\tprintf(\"                      options are:  'inferno', 'inferno-inverted',\\n\");\r\n",
        "\tprintf(\"                                    'magma', 'magma-inverted',\\n\");\r\n",
        "\tprintf(\"                                    'parula', 'parula-inverted',\\n\");\r\n",
        "\tprintf(\"                                    'plasma', 'plasma-inverted',\\n\");\r\n",
        "\tprintf(\"                                    'turbo', 'turbo-inverted',\\n\");\r\n",
        "\tprintf(\"                                    'viridis', 'viridis-inverted'\\n\\n\");\r\n",
        "\tprintf(\"positional arguments:\\n\");\r\n",
        "\tprintf(\"    input_URI       resource URI of input stream  (see videoSource below)\\n\");\r\n",
        "\tprintf(\"    output_URI      resource URI of output stream (see videoOutput below)\\n\\n\");\r\n",
        "\r\n",
        "\tprintf(\"%s\", depthNet::Usage());\r\n",
        "\tprintf(\"%s\", videoSource::Usage());\r\n",
        "\tprintf(\"%s\", videoOutput::Usage());\r\n",
        "\tprintf(\"%s\", Log::Usage());\r\n",
        "\t\r\n",
        "\treturn 0;\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "//\r\n",
        "// depth map buffers\r\n",
        "//\r\n",
        "typedef uchar3 pixelType;        // this can be uchar3, uchar4, float3, float4\r\n",
        "\r\n",
        "pixelType* imgDepth = NULL;      // colorized depth map image\r\n",
        "pixelType* imgComposite = NULL;  // original image with depth map next to it\r\n",
        "\r\n",
        "int2 inputSize;\r\n",
        "int2 depthSize;\r\n",
        "int2 compositeSize;\r\n",
        "\r\n",
        "// allocate depth map & output buffers\r\n",
        "bool allocBuffers( int width, int height, uint32_t flags, float depthScale )\r\n",
        "{\r\n",
        "\t// check if the buffers were already allocated for this size\r\n",
        "\tif( imgDepth != NULL && width == inputSize.x && height == inputSize.y )\r\n",
        "\t\treturn true;\r\n",
        "\r\n",
        "\t// free previous buffers if they exit\r\n",
        "\tCUDA_FREE_HOST(imgDepth);\r\n",
        "\tCUDA_FREE_HOST(imgComposite);\r\n",
        "\r\n",
        "\t// allocate depth map\r\n",
        "\tinputSize = make_int2(width, height);\r\n",
        "\tdepthSize = make_int2(width * depthScale, height * depthScale);\r\n",
        "\t\r\n",
        "\tif( !cudaAllocMapped(&imgDepth, depthSize) )\r\n",
        "\t{\r\n",
        "\t\tLogError(\"depthnet:  failed to allocate CUDA memory for depth map (%ix%i)\\n\", depthSize.x, depthSize.y);\r\n",
        "\t\treturn false;\r\n",
        "\t}\r\n",
        "\r\n",
        "\t// allocate composite image\r\n",
        "\tcompositeSize = make_int2(0,0);\r\n",
        "\t\r\n",
        "\tif( flags & depthNet::VISUALIZE_DEPTH )\r\n",
        "\t{\r\n",
        "\t\tcompositeSize.x += depthSize.x;\r\n",
        "\t\tcompositeSize.y = depthSize.y;\r\n",
        "\t}\r\n",
        "\t\r\n",
        "\tif( flags & depthNet::VISUALIZE_INPUT )\r\n",
        "\t{\r\n",
        "\t\tcompositeSize.x += inputSize.x;\r\n",
        "\t\tcompositeSize.y = inputSize.y;\r\n",
        "\t}\r\n",
        "\t\r\n",
        "\tif( !cudaAllocMapped(&imgComposite, compositeSize) )\r\n",
        "\t{\r\n",
        "\t\tLogError(\"depthnet:  failed to allocate CUDA memory for composite image (%ix%i)\\n\", compositeSize.x, compositeSize.y);\r\n",
        "\t\treturn false;\r\n",
        "\t}\r\n",
        "\r\n",
        "\treturn true;\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "int main( int argc, char** argv )\r\n",
        "{\r\n",
        "\t/*\r\n",
        "\t * parse command line\r\n",
        "\t */\r\n",
        "\tcommandLine cmdLine(argc, argv);\r\n",
        "\r\n",
        "\tif( cmdLine.GetFlag(\"help\") )\r\n",
        "\t\treturn usage();\r\n",
        "\r\n",
        "\t\r\n",
        "\t/*\r\n",
        "\t * attach signal handler\r\n",
        "\t */\r\n",
        "\tif( signal(SIGINT, sig_handler) == SIG_ERR )\r\n",
        "\t\tLogError(\"can't catch SIGINT\\n\");\r\n",
        "\r\n",
        "\r\n",
        "\t/*\r\n",
        "\t * create input stream\r\n",
        "\t */\r\n",
        "\tvideoSource* input = videoSource::Create(cmdLine, ARG_POSITION(0));\r\n",
        "\r\n",
        "\tif( !input )\r\n",
        "\t{\r\n",
        "\t\tLogError(\"depthnet:  failed to create input stream\\n\");\r\n",
        "\t\treturn 0;\r\n",
        "\t}\r\n",
        "\r\n",
        "\r\n",
        "\t/*\r\n",
        "\t * create output stream\r\n",
        "\t */\r\n",
        "\tvideoOutput* output = videoOutput::Create(cmdLine, ARG_POSITION(1));\r\n",
        "\t\r\n",
        "\tif( !output )\r\n",
        "\t\tLogError(\"depthnet:  failed to create output stream\\n\");\r\n",
        "\t\r\n",
        "\r\n",
        "\t/*\r\n",
        "\t * create mono-depth network\r\n",
        "\t */\r\n",
        "\tdepthNet* net = depthNet::Create(cmdLine);\r\n",
        "\r\n",
        "\tif( !net )\r\n",
        "\t{\r\n",
        "\t\tLogError(\"depthnet:   failed to initialize depthNet\\n\");\r\n",
        "\t\treturn 0;\r\n",
        "\t}\r\n",
        "\r\n",
        "\t// parse the desired colormap\r\n",
        "\tconst cudaColormapType colormap = cudaColormapFromStr(cmdLine.GetString(\"colormap\", \"viridis-inverted\"));\r\n",
        "\r\n",
        "\t// parse the desired filter mode\r\n",
        "\tconst cudaFilterMode filterMode = cudaFilterModeFromStr(cmdLine.GetString(\"filter-mode\"));\r\n",
        "\r\n",
        "\t// parse the visualization flags\r\n",
        "\tconst uint32_t visualizationFlags = depthNet::VisualizationFlagsFromStr(cmdLine.GetString(\"visualize\"));\r\n",
        "\t\r\n",
        "\t// get the depth map size scaling factor\r\n",
        "\tconst float depthScale = cmdLine.GetFloat(\"depth-size\", 1.0);\r\n",
        "\r\n",
        "\r\n",
        "\t/*\r\n",
        "\t * processing loop\r\n",
        "\t */\r\n",
        "\twhile( !signal_recieved )\r\n",
        "\t{\r\n",
        "\t\t// capture next image image\r\n",
        "\t\tpixelType* imgInput = NULL;\r\n",
        "\r\n",
        "\t\tif( !input->Capture(&imgInput, 1000) )\r\n",
        "\t\t{\r\n",
        "\t\t\t// check for EOS\r\n",
        "\t\t\tif( !input->IsStreaming() )\r\n",
        "\t\t\t\tbreak;\r\n",
        "\r\n",
        "\t\t\tLogError(\"depthnet:  failed to capture next frame\\n\");\r\n",
        "\t\t\tcontinue;\r\n",
        "\t\t}\r\n",
        "\r\n",
        "\t\t// allocate buffers for this size frame\r\n",
        "\t\tif( !allocBuffers(input->GetWidth(), input->GetHeight(), visualizationFlags, depthScale) )\r\n",
        "\t\t{\r\n",
        "\t\t\tLogError(\"depthnet:  failed to allocate output buffers\\n\");\r\n",
        "\t\t\tcontinue;\r\n",
        "\t\t}\r\n",
        "\t\t\r\n",
        "\t\t// infer the depth and visualize the depth map\r\n",
        "\t\tif( !net->Process(imgInput, inputSize.x, inputSize.y, \r\n",
        "\t\t\t\t\t   imgDepth, depthSize.x, depthSize.y, \r\n",
        "\t\t\t\t\t   colormap, filterMode) )\r\n",
        "\t\t{\r\n",
        "\t\t\tLogError(\"depthnet-camera:  failed to process depth map\\n\");\r\n",
        "\t\t\tcontinue;\r\n",
        "\t\t}\r\n",
        "\r\n",
        "\t\t// overlay the images into composite output image\r\n",
        "\t\tif( visualizationFlags & depthNet::VISUALIZE_INPUT )\r\n",
        "\t\t\tCUDA(cudaOverlay(imgInput, inputSize, imgComposite, compositeSize, 0, 0));\r\n",
        "\t\t\r\n",
        "\t\tif( visualizationFlags & depthNet::VISUALIZE_DEPTH )\r\n",
        "\t\t\tCUDA(cudaOverlay(imgDepth, depthSize, imgComposite, compositeSize, (visualizationFlags & depthNet::VISUALIZE_INPUT) ? inputSize.x : 0, 0));\r\n",
        "\t\t\r\n",
        "\t\t// render outputs\r\n",
        "\t\tif( output != NULL )\r\n",
        "\t\t{\r\n",
        "\t\t\toutput->Render(imgComposite, compositeSize.x, compositeSize.y);\r\n",
        "\r\n",
        "\t\t\t// update the status bar\r\n",
        "\t\t\tchar str[256];\r\n",
        "\t\t\tsprintf(str, \"TensorRT %i.%i.%i | %s | Network %.0f FPS\", NV_TENSORRT_MAJOR, NV_TENSORRT_MINOR, NV_TENSORRT_PATCH, net->GetNetworkName(), net->GetNetworkFPS());\r\n",
        "\t\t\toutput->SetStatus(str);\r\n",
        "\r\n",
        "\t\t\t// check if the user quit\r\n",
        "\t\t\tif( !output->IsStreaming() )\r\n",
        "\t\t\t\tsignal_recieved = true;\r\n",
        "\t\t}\r\n",
        "\r\n",
        "\t\t// wait for the GPU to finish\t\t\r\n",
        "\t\tCUDA(cudaDeviceSynchronize());\r\n",
        "\r\n",
        "\t\t// print out timing info\r\n",
        "\t\tnet->PrintProfilerTimes();\r\n",
        "\t}\r\n",
        "\t\r\n",
        "\r\n",
        "\t/*\r\n",
        "\t * destroy resources\r\n",
        "\t */\r\n",
        "\tLogVerbose(\"depthnet:  shutting down...\\n\");\r\n",
        "\t\r\n",
        "\tSAFE_DELETE(input);\r\n",
        "\tSAFE_DELETE(output);\r\n",
        "\tSAFE_DELETE(net);\r\n",
        "\t\r\n",
        "\tCUDA_FREE_HOST(imgDepth);\r\n",
        "\tCUDA_FREE_HOST(imgComposite);\r\n",
        "\r\n",
        "\tLogVerbose(\"depthnet:  shutdown complete.\\n\");\r\n",
        "\treturn 0;\r\n",
        "}\r\n",
        "\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Editar el CMakeList.txt con lo siguiente\r\n",
        "\r\n",
        "```\r\n",
        "# require CMake 2.8 or greater\r\n",
        "cmake_minimum_required(VERSION 2.8)\r\n",
        "\r\n",
        "# declare my-depth project\r\n",
        "project(my-depth)\r\n",
        "\r\n",
        "# import jetson-inference and jetson-utils packages.\r\n",
        "# note that if you didn't do \"sudo make install\"\r\n",
        "# while building jetson-inference, this will error.\r\n",
        "find_package(jetson-utils)\r\n",
        "find_package(jetson-inference)\r\n",
        "\r\n",
        "# CUDA and Qt4 are required\r\n",
        "find_package(CUDA)\r\n",
        "find_package(Qt4)\r\n",
        "\r\n",
        "# setup Qt4 for build\r\n",
        "include(${QT_USE_FILE})\r\n",
        "add_definitions(${QT_DEFINITIONS})\r\n",
        "\r\n",
        "# compile the my-depth program\r\n",
        "cuda_add_executable(my-depth my-depth.cpp)\r\n",
        "\r\n",
        "# link my-depth to jetson-inference library\r\n",
        "target_link_libraries(my-depth jetson-inference)\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilar el código con los siguientes comandos\r\n",
        "\r\n",
        "```\r\n",
        "$ cmake .\r\n",
        "$ make\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecutar el programa con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ ./my-depth /dev/video0\r\n",
        "```\r\n",
        "\r\n",
        "En este caso abrirá la webcam, se pueden introducir las mismas variables que con el programa precompilado"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.11 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "d1c24abb23a313e1f9ae042292cd8e6e3c60c5818227ced3d46e3df2c65171ef"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}