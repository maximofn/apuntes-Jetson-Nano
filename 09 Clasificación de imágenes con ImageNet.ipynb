{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clasificación de imágenes con ImageNet"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "La lista de objetos que se pueden clasificar mediante las redes preentrenadas se encuentra en este [enlace](https://github.com/dusty-nv/jetson-inference/blob/master/data/networks/ilsvrc12_synset_words.txt)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uso de los programas precompilados de la Jetson"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí se pueden encontrar los códigos de los programas precompilados:\r\n",
        " * [C++](https://github.com/dusty-nv/jetson-inference/blob/master/examples/imagenet/imagenet.cpp)\r\n",
        " * [Python](https://github.com/dusty-nv/jetson-inference/blob/master/python/examples/imagenet.py)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ir a la carpeta con los programas precompilados con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ cd jetson-inference/build/aarch64/bin\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, clasifiquemos una imagen de ejemplo con el programap precompilado imagenet, tanto en C++ como en Python. Si está utilizando el contenedor Docker, es recomendable guardar la imagen de salida clasificada en el directorio images/test. Estas imágenes se podrán ver fácilmente desde su dispositivo host en el directorio jetson-inference/data/images/test.\r\n",
        "\r\n",
        "```\r\n",
        "# C++\r\n",
        "$ ./imagenet images/orange_0.jpg images/test/orange_0.jpg     # (default network is googlenet)\r\n",
        "\r\n",
        "# Python\r\n",
        "$ ./imagenet.py images/orange_0.jpg images/test/orange_0.jpg  # (default network is googlenet)\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si queremos clasificar varias imágenes\r\n",
        "\r\n",
        "```\r\n",
        "# C++\r\n",
        "$ ./imagenet \"images/object_*.jpg\" \"images/test/object_%i.jpg\"     # (default network is googlenet)\r\n",
        "\r\n",
        "# Python\r\n",
        "$ ./imagenet.py \"images/object_*.jpg\" \"images/test/object_%i.jpg\"  # (default network is googlenet)\r\n",
        "```\r\n",
        "\r\n",
        " > **nota**: cuando se usen asteriscos, hay que escribirlos siempre entre comillas (\"*.jpg\"). De lo contrario, el sistema operativo expandirá automáticamente la secuencia y modificará el orden de los argumentos en la línea de comandos, lo que puede resultar en que una de las imágenes de entrada sea sobrescrita por la salida."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si queremos usar otras redes (por defecto se usa GoogleNet) hay que usar el flag ```--network```\r\n",
        "\r\n",
        "```\r\n",
        "# C++\r\n",
        "$ ./imagenet --network=resnet-18 \"images/cat_*.jpg\" \"images/test/cat_%i.jpg\"     # (default network is googlenet)\r\n",
        "\r\n",
        "# Python\r\n",
        "$ ./imagenet.py --network=resnet-18 \"images/cat_*.jpg\" \"images/test/cat_%i.jpg\"  # (default network is googlenet)\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las redes que podemos usar para clasificación son:\r\n",
        "|Network|argumento CLI|Network Type enum|\r\n",
        "|------|--------------|-----------------|\r\n",
        "|AlexNet|alexnet|ALEXNET|\r\n",
        "|GoogleNet|googlenet|GOOGLENET|\r\n",
        "|GoogleNet-12|googlenet-12|GOOGLENET_12|\r\n",
        "|ResNet-18|resnet-18|RESNET_18|\r\n",
        "|ResNet-50|resnet-50|RESNET_50|\r\n",
        "|ResNet-101|resnet-101|RESNET_101|\r\n",
        "|ResNet-152|resnet-152|RESNET_152|\r\n",
        "|VGG-16|vgg-16|VGG-16|\r\n",
        "|VGG-19|vgg-19|VGG-19|\r\n",
        "|Inception-v4|inception-v4|INCEPTION_V4|"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si se quiere procesar un videdo solo hay que indicarlo en la entrada\r\n",
        "\r\n",
        "Primero lo descargamos\r\n",
        "\r\n",
        "```\r\n",
        "# Download test video (thanks to jell.yfish.us)\r\n",
        "$ wget https://nvidia.box.com/shared/static/tlswont1jnyu3ix2tbf7utaekpzcx4rc.mkv -O jellyfish.mkv\r\n",
        "```\r\n",
        "\r\n",
        "Y ya lo podemos procesar\r\n",
        "\r\n",
        "```\r\n",
        "# C++\r\n",
        "$ ./imagenet --network=resnet-18 jellyfish.mkv images/test/jellyfish_resnet18.mkv\r\n",
        "\r\n",
        "# Python\r\n",
        "$ ./imagenet.py --network=resnet-18 jellyfish.mkv images/test/jellyfish_resnet18.mkv\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crear un programa de clasificación en Python"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como vamos a crear un programa, lo primero que tenemos que hacer es crear una carpeta en el Host donde guardaremos el programa\r\n",
        "\r\n",
        "```\r\n",
        "$ cd ~/\r\n",
        "$ mkdir my-recognition-python\r\n",
        "$ cd my-recognition-python\r\n",
        "$ touch my-recognition.py\r\n",
        "$ chmod +x my-recognition.py\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nos descargamos unas imágenes de osos para probar\r\n",
        "\r\n",
        "```\r\n",
        "$ wget https://github.com/dusty-nv/jetson-inference/raw/master/data/images/black_bear.jpg \r\n",
        "$ wget https://github.com/dusty-nv/jetson-inference/raw/master/data/images/brown_bear.jpg\r\n",
        "$ wget https://github.com/dusty-nv/jetson-inference/raw/master/data/images/polar_bear.jpg\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación lo que hay que hacer es lanzar el Docker con una carpeta del Host compartida, para que así cuando se cierre el Docker no se borre el programa, para ello lanzamos el Docker con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ docker/run.sh --volume ~/my-recognition-python:/my-recognition-python   # mounted inside the container to /my-recognition-python \r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez dentro del Docker ir a la carpeta con los siguientes comandos\r\n",
        "\r\n",
        "```\r\n",
        "$ cd ../\r\n",
        "$ cd my-recognition-python\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Editar el archivo .py con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ nano my-recognition.py\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para crear un programa como el precompilado escribimos el siguiente código\r\n",
        "\r\n",
        "```Python\r\n",
        "import jetson.inference\r\n",
        "import jetson.utils\r\n",
        "\r\n",
        "import argparse\r\n",
        "import sys\r\n",
        "\r\n",
        "\r\n",
        "# parse the command line\r\n",
        "parser = argparse.ArgumentParser(description=\"Classify a live camera stream using an image recognition DNN.\", \r\n",
        "                                 formatter_class=argparse.RawTextHelpFormatter, epilog=jetson.inference.imageNet.Usage() +\r\n",
        "                                 jetson.utils.videoSource.Usage() + jetson.utils.videoOutput.Usage() + jetson.utils.logUsage())\r\n",
        "\r\n",
        "parser.add_argument(\"input_URI\", type=str, default=\"\", nargs='?', help=\"URI of the input stream\")\r\n",
        "parser.add_argument(\"output_URI\", type=str, default=\"\", nargs='?', help=\"URI of the output stream\")\r\n",
        "parser.add_argument(\"--network\", type=str, default=\"googlenet\", help=\"pre-trained model to load (see below for options)\")\r\n",
        "parser.add_argument(\"--camera\", type=str, default=\"0\", help=\"index of the MIPI CSI camera to use (e.g. CSI camera 0)\\nor for VL42 cameras, the /dev/video device to use.\\nby default, MIPI CSI camera 0 will be used.\")\r\n",
        "parser.add_argument(\"--width\", type=int, default=1280, help=\"desired width of camera stream (default is 1280 pixels)\")\r\n",
        "parser.add_argument(\"--height\", type=int, default=720, help=\"desired height of camera stream (default is 720 pixels)\")\r\n",
        "parser.add_argument('--headless', action='store_true', default=(), help=\"run without display\")\r\n",
        "\r\n",
        "is_headless = [\"--headless\"] if sys.argv[0].find('console.py') != -1 else [\"\"]\r\n",
        "\r\n",
        "try:\r\n",
        "\topt = parser.parse_known_args()[0]\r\n",
        "except:\r\n",
        "\tprint(\"\")\r\n",
        "\tparser.print_help()\r\n",
        "\tsys.exit(0)\r\n",
        "\r\n",
        "\r\n",
        "# load the recognition network\r\n",
        "net = jetson.inference.imageNet(opt.network, sys.argv)\r\n",
        "\r\n",
        "# create video sources & outputs\r\n",
        "input = jetson.utils.videoSource(opt.input_URI, argv=sys.argv)\r\n",
        "output = jetson.utils.videoOutput(opt.output_URI, argv=sys.argv+is_headless)\r\n",
        "font = jetson.utils.cudaFont()\r\n",
        "\r\n",
        "# process frames until the user exits\r\n",
        "while True:\r\n",
        "\t# capture the next image\r\n",
        "\timg = input.Capture()\r\n",
        "\r\n",
        "\t# classify the image\r\n",
        "\tclass_id, confidence = net.Classify(img)\r\n",
        "\r\n",
        "\t# find the object description\r\n",
        "\tclass_desc = net.GetClassDesc(class_id)\r\n",
        "\r\n",
        "\t# overlay the result on the image\t\r\n",
        "\tfont.OverlayText(img, img.width, img.height, \"{:05.2f}% {:s}, {:s} | Network {:.0f} FPS\".format(confidence * 100, class_desc, net.GetNetworkName(), net.GetNetworkFPS()), 5, 5, font.White, font.Gray40)\r\n",
        "\t\r\n",
        "\t# render the image\r\n",
        "\toutput.Render(img)\r\n",
        "\r\n",
        "\t# update the title bar\r\n",
        "\toutput.SetStatus(\"{:s} | Network {:.0f} FPS\".format(net.GetNetworkName(), net.GetNetworkFPS()))\r\n",
        "\r\n",
        "\t# print out performance info\r\n",
        "\tnet.PrintProfilerTimes()\r\n",
        "\r\n",
        "\t# exit on input/output EOS\r\n",
        "\tif not input.IsStreaming() or not output.IsStreaming():\r\n",
        "\t\tbreak\r\n",
        "\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecutar el programa con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ python3 my-recognition.py /dev/video0\r\n",
        "```\r\n",
        "\r\n",
        "En este caso abrirá la webcam, se pueden introducir las mismas variables que con el programa precompilado"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crear un programa ded clasificación en C++"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como vamos a crear un programa, lo primero que tenemos que hacer es crear una carpeta en el Host donde guardaremos el programa\r\n",
        "\r\n",
        "```\r\n",
        "$ cd ~/\r\n",
        "$ mkdir my-recognition-cpp\r\n",
        "$ cd my-recognition-cpp\r\n",
        "$ touch my-recognition.cpp\r\n",
        "$ chmod +x my-recognition.cpp\r\n",
        "$ touch CMakeLists.txt\r\n",
        "$ chmod +x CMakeLists.txt\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nos descargamos unas imágenes de osos para probar\r\n",
        "\r\n",
        "```\r\n",
        "$ wget https://github.com/dusty-nv/jetson-inference/raw/master/data/images/black_bear.jpg \r\n",
        "$ wget https://github.com/dusty-nv/jetson-inference/raw/master/data/images/brown_bear.jpg\r\n",
        "$ wget https://github.com/dusty-nv/jetson-inference/raw/master/data/images/polar_bear.jpg\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación lo que hay que hacer es lanzar el Docker con una carpeta del Host compartida, para que así cuando se cierre el Docker no se borre el programa, para ello lanzamos el Docker con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ docker/run.sh --volume ~/my-recognition-cpp:/my-recognition-cpp   # mounted inside the container to /my-recognition-cpp\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez dentro del Docker ir a la carpeta con los siguientes comandos\r\n",
        "\r\n",
        "```\r\n",
        "$ cd ../\r\n",
        "$ cd my-recognition-cpp\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Editar el archivo .py con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ nano my-recognition.cpp\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para crear un programa como el precompilado escribimos el siguiente código\r\n",
        "\r\n",
        "```C++\r\n",
        "#include <jetson-utils/videoSource.h>\r\n",
        "#include <jetson-utils/videoOutput.h>\r\n",
        "\r\n",
        "#include <jetson-utils/cudaFont.h>\r\n",
        "#include <jetson-inference/imageNet.h>\r\n",
        "\r\n",
        "#include <signal.h>\r\n",
        "\r\n",
        "\r\n",
        "#ifdef HEADLESS\r\n",
        "\t#define IS_HEADLESS() \"headless\"\t// run without display\r\n",
        "#else\r\n",
        "\t#define IS_HEADLESS() (const char*)NULL\r\n",
        "#endif\r\n",
        "\r\n",
        "\r\n",
        "bool signal_recieved = false;\r\n",
        "\r\n",
        "void sig_handler(int signo)\r\n",
        "{\r\n",
        "\tif( signo == SIGINT )\r\n",
        "\t{\r\n",
        "\t\tLogVerbose(\"received SIGINT\\n\");\r\n",
        "\t\tsignal_recieved = true;\r\n",
        "\t}\r\n",
        "}\r\n",
        "\r\n",
        "int usage()\r\n",
        "{\r\n",
        "\tprintf(\"usage: imagenet [--help] [--network=NETWORK] ...\\n\");\r\n",
        "\tprintf(\"                input_URI [output_URI]\\n\\n\");\r\n",
        "\tprintf(\"Classify a video/image stream using an image recognition DNN.\\n\");\r\n",
        "\tprintf(\"See below for additional arguments that may not be shown above.\\n\\n\");\t\r\n",
        "\tprintf(\"positional arguments:\\n\");\r\n",
        "\tprintf(\"    input_URI       resource URI of input stream  (see videoSource below)\\n\");\r\n",
        "\tprintf(\"    output_URI      resource URI of output stream (see videoOutput below)\\n\\n\");\r\n",
        "\r\n",
        "\tprintf(\"%s\", imageNet::Usage());\r\n",
        "\tprintf(\"%s\", videoSource::Usage());\r\n",
        "\tprintf(\"%s\", videoOutput::Usage());\r\n",
        "\tprintf(\"%s\", Log::Usage());\r\n",
        "\r\n",
        "\treturn 0;\r\n",
        "}\r\n",
        "\r\n",
        "int main( int argc, char** argv )\r\n",
        "{\r\n",
        "\t/*\r\n",
        "\t * parse command line\r\n",
        "\t */\r\n",
        "\tcommandLine cmdLine(argc, argv, IS_HEADLESS());\r\n",
        "\r\n",
        "\tif( cmdLine.GetFlag(\"help\") )\r\n",
        "\t\treturn usage();\r\n",
        "\r\n",
        "\r\n",
        "\t/*\r\n",
        "\t * attach signal handler\r\n",
        "\t */\r\n",
        "\tif( signal(SIGINT, sig_handler) == SIG_ERR )\r\n",
        "\t\tLogError(\"can't catch SIGINT\\n\");\r\n",
        "\r\n",
        "\r\n",
        "\t/*\r\n",
        "\t * create input stream\r\n",
        "\t */\r\n",
        "\tvideoSource* input = videoSource::Create(cmdLine, ARG_POSITION(0));\r\n",
        "\r\n",
        "\tif( !input )\r\n",
        "\t{\r\n",
        "\t\tLogError(\"imagenet:  failed to create input stream\\n\");\r\n",
        "\t\treturn 0;\r\n",
        "\t}\r\n",
        "\r\n",
        "\r\n",
        "\t/*\r\n",
        "\t * create output stream\r\n",
        "\t */\r\n",
        "\tvideoOutput* output = videoOutput::Create(cmdLine, ARG_POSITION(1));\r\n",
        "\t\r\n",
        "\tif( !output )\r\n",
        "\t\tLogError(\"imagenet:  failed to create output stream\\n\");\t\r\n",
        "\t\r\n",
        "\r\n",
        "\t/*\r\n",
        "\t * create font for image overlay\r\n",
        "\t */\r\n",
        "\tcudaFont* font = cudaFont::Create();\r\n",
        "\t\r\n",
        "\tif( !font )\r\n",
        "\t{\r\n",
        "\t\tLogError(\"imagenet:  failed to load font for overlay\\n\");\r\n",
        "\t\treturn 0;\r\n",
        "\t}\r\n",
        "\r\n",
        "\r\n",
        "\t/*\r\n",
        "\t * create recognition network\r\n",
        "\t */\r\n",
        "\timageNet* net = imageNet::Create(cmdLine);\r\n",
        "\t\r\n",
        "\tif( !net )\r\n",
        "\t{\r\n",
        "\t\tLogError(\"imagenet:  failed to initialize imageNet\\n\");\r\n",
        "\t\treturn 0;\r\n",
        "\t}\r\n",
        "\r\n",
        "\r\n",
        "\t/*\r\n",
        "\t * processing loop\r\n",
        "\t */\r\n",
        "\twhile( !signal_recieved )\r\n",
        "\t{\r\n",
        "\t\t// capture next image image\r\n",
        "\t\tuchar3* image = NULL;\r\n",
        "\r\n",
        "\t\tif( !input->Capture(&image, 1000) )\r\n",
        "\t\t{\r\n",
        "\t\t\t// check for EOS\r\n",
        "\t\t\tif( !input->IsStreaming() )\r\n",
        "\t\t\t\tbreak;\r\n",
        "\r\n",
        "\t\t\tLogError(\"imagenet:  failed to capture next frame\\n\");\r\n",
        "\t\t\tcontinue;\r\n",
        "\t\t}\r\n",
        "\r\n",
        "\t\t// classify image\r\n",
        "\t\tfloat confidence = 0.0f;\r\n",
        "\t\tconst int img_class = net->Classify(image, input->GetWidth(), input->GetHeight(), &confidence);\r\n",
        "\t\r\n",
        "\t\tif( img_class >= 0 )\r\n",
        "\t\t{\r\n",
        "\t\t\tLogVerbose(\"imagenet:  %2.5f%% class #%i (%s)\\n\", confidence * 100.0f, img_class, net->GetClassDesc(img_class));\t\r\n",
        "\r\n",
        "\t\t\tif( font != NULL )\r\n",
        "\t\t\t{\r\n",
        "\t\t\t\tchar str[256];\r\n",
        "\t\t\t\tsprintf(str, \"%05.2f%% %s\", confidence * 100.0f, net->GetClassDesc(img_class));\r\n",
        "\t\r\n",
        "\t\t\t\tfont->OverlayText(image, input->GetWidth(), input->GetHeight(),\r\n",
        "\t\t\t\t\t\t        str, 5, 5, make_float4(255, 255, 255, 255), make_float4(0, 0, 0, 100));\r\n",
        "\t\t\t}\r\n",
        "\t\t}\t\r\n",
        "\r\n",
        "\t\t// render outputs\r\n",
        "\t\tif( output != NULL )\r\n",
        "\t\t{\r\n",
        "\t\t\toutput->Render(image, input->GetWidth(), input->GetHeight());\r\n",
        "\r\n",
        "\t\t\t// update status bar\r\n",
        "\t\t\tchar str[256];\r\n",
        "\t\t\tsprintf(str, \"TensorRT %i.%i.%i | %s | Network %.0f FPS\", NV_TENSORRT_MAJOR, NV_TENSORRT_MINOR, NV_TENSORRT_PATCH, net->GetNetworkName(), net->GetNetworkFPS());\r\n",
        "\t\t\toutput->SetStatus(str);\t\r\n",
        "\r\n",
        "\t\t\t// check if the user quit\r\n",
        "\t\t\tif( !output->IsStreaming() )\r\n",
        "\t\t\t\tsignal_recieved = true;\r\n",
        "\t\t}\r\n",
        "\r\n",
        "\t\t// print out timing info\r\n",
        "\t\tnet->PrintProfilerTimes();\r\n",
        "\t}\r\n",
        "\t\r\n",
        "\t\r\n",
        "\t/*\r\n",
        "\t * destroy resources\r\n",
        "\t */\r\n",
        "\tLogVerbose(\"imagenet:  shutting down...\\n\");\r\n",
        "\t\r\n",
        "\tSAFE_DELETE(input);\r\n",
        "\tSAFE_DELETE(output);\r\n",
        "\tSAFE_DELETE(net);\r\n",
        "\t\r\n",
        "\tLogVerbose(\"imagenet:  shutdown complete.\\n\");\r\n",
        "\treturn 0;\r\n",
        "}\r\n",
        "\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Editar el CMakeList.txt con lo siguiente\r\n",
        "\r\n",
        "```\r\n",
        "# require CMake 2.8 or greater\r\n",
        "cmake_minimum_required(VERSION 2.8)\r\n",
        "\r\n",
        "# declare my-recognition project\r\n",
        "project(my-recognition)\r\n",
        "\r\n",
        "# import jetson-inference and jetson-utils packages.\r\n",
        "# note that if you didn't do \"sudo make install\"\r\n",
        "# while building jetson-inference, this will error.\r\n",
        "find_package(jetson-utils)\r\n",
        "find_package(jetson-inference)\r\n",
        "\r\n",
        "# CUDA and Qt4 are required\r\n",
        "find_package(CUDA)\r\n",
        "find_package(Qt4)\r\n",
        "\r\n",
        "# setup Qt4 for build\r\n",
        "include(${QT_USE_FILE})\r\n",
        "add_definitions(${QT_DEFINITIONS})\r\n",
        "\r\n",
        "# compile the my-recognition program\r\n",
        "cuda_add_executable(my-recognition my-recognition.cpp)\r\n",
        "\r\n",
        "# link my-recognition to jetson-inference library\r\n",
        "target_link_libraries(my-recognition jetson-inference)\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilar el código con los siguientes comandos\r\n",
        "\r\n",
        "```\r\n",
        "$ cmake .\r\n",
        "$ make\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecutar el programa con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ ./my-recognition /dev/video0\r\n",
        "```\r\n",
        "\r\n",
        "En este caso abrirá la webcam, se pueden introducir las mismas variables que con el programa precompilado"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.11 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "d1c24abb23a313e1f9ae042292cd8e6e3c60c5818227ced3d46e3df2c65171ef"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}