{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Estimación de pose con PoseNet"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "La estimación de pose consiste en localizar varias partes del cuerpo (también conocidas como puntos clave (keypoints)) que forman una topología esquelética (también conocida como enlaces (links)). La estimación de pose tiene una variedad de aplicaciones que incluyen gestos, AR/VR, HMI (interfaz hombre/máquina) y corrección de postura/marcha."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "``PoseNet`` acepta una imagen como entrada y genera una lista de objetos de pose. Cada objeto de pose contiene una lista de puntos clave detectados, junto con sus ubicaciones y vínculos entre puntos clave."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uso de los programas precompilados de la Jetson"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí se pueden encontrar los códigos de los programas precompilados:\r\n",
        " * [C++](https://github.com/dusty-nv/jetson-inference/blob/master/examples/posenet/posenet.cpp)\r\n",
        " * [Python](https://github.com/dusty-nv/jetson-inference/blob/master/python/examples/posenet.py)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelos de estimación de pose pre-entrenados disponibles"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, se muestran las redes de estimación de pose previamente entrenadas disponibles para descargar y el argumento ``--network`` asociado que se ``PoseNet`` utilizará para cargar los modelos previamente entrenados:\r\n",
        "\r\n",
        "|Model|CLI argument|NetworkType enum|Keypoints|\r\n",
        "|-------|----------|----------|--------|\r\n",
        "|Pose-ResNet18-Body|``resnet18-body``|``RESNET18_BODY``|18|\r\n",
        "|Pose-ResNet18-Hand|``resnet18-hand``|``RESNET18_HAND``|21|\r\n",
        "|Pose-DenseNet121-Body|``densenet121-body``|``DENSENET121_BODY``|18|"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uso de los programas precompilados de la Jetson"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Además de las rutas de entrada/salida, hay algunas opciones de línea de comandos adicionales:\r\n",
        "\r\n",
        " * flag ``--network`` (opcional) cambia el modelo de pose que se está utilizando (el valor predeterminado es ``resnet18-body``)\r\n",
        " * flag ``--overlay`` (opcional) acepta combinaciones separada por comas de ``box``, ``links``, ``keypoints`` y ``none`` (el valor predeterminado es ``links,keypoints``)\r\n",
        " * flag ``--keypoint-scale`` (opcional) establece el radio de los círculos de puntos clave en la superposición ``overlay`` (el valor predeterminado es 0.0052)\r\n",
        " * flag ``--link-scale`` (opcional) establece el ancho de línea de las líneas de enlace en la superposición ``overlay`` (el valor predeterminado es 0.0013)\r\n",
        " * flag ``--threshold`` (opcional) establece el umbral mínimo de detección (el valor predeterminado es 0.15)\r\n",
        "\r\n",
        "Usar el flag ``--help`` para obtener más información"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ir a la carpeta con los programas precompilados con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ cd jetson-inference/build/aarch64/bin\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Procesamiento de una imagen"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, detectemos objetos en una imagen de ejemplo con el programap precompilado ``poseNet``, tanto en C++ como en Python. Si está utilizando el contenedor Docker, es recomendable guardar la imagen de salida en el directorio images/test. Estas imágenes se podrán ver fácilmente desde su dispositivo host en el directorio jetson-inference/data/images/test.\r\n",
        "\r\n",
        "```\r\n",
        "# C++\r\n",
        "$ ./posenet images/humans_0.jpg images/test/humans_0.jpg\r\n",
        "\r\n",
        "# Python\r\n",
        "$ ./posenet.py images/humans_0.jpg images/test/humans_0.jpg\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Procesamiento de varias imágenes"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si queremos detectar varias imágenes\r\n",
        "\r\n",
        "```\r\n",
        "# C++\r\n",
        "$ ./posenet \"images/humans_*.jpg\" images/test/humans_%i.jpg\r\n",
        "\r\n",
        "# Python\r\n",
        "$ ./posenet.py \"images/humans_*.jpg\" images/test/humans_%i.jpg\r\n",
        "```\r\n",
        "\r\n",
        " > **nota**: cuando se usen asteriscos, hay que escribirlos siempre entre comillas (\"*.jpg\"). De lo contrario, el sistema operativo expandirá automáticamente la secuencia y modificará el orden de los argumentos en la línea de comandos, lo que puede resultar en que una de las imágenes de entrada sea sobrescrita por la salida."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Red"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si queremos cambiar el tipo de red flag `--network` (por defecto `resnet18-body`)\r\n",
        "\r\n",
        "```\r\n",
        "# C++\r\n",
        "$ ./posenet --network=resnet18-hand images/humans_3.jpg images/test/humans_3.jpg    # resnet18-hand network\r\n",
        "$ ./posenet --network=densenet121-body images/humans_2.jpg images/test/humans_2.jpg # densenet121-body network\r\n",
        "\r\n",
        "# Python\r\n",
        "$ ./posenet.py --network=resnet18-hand images/humans_3.jpg images/test/humans_3.jpg    # resnet18-hand network\r\n",
        "$ ./posenet.py --network=densenet121-body images/humans_2.jpg images/test/humans_2.jpg # densenet121-body network\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overlay"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede cambiar el modo de visualización es mediante el flag `--overlay`, se puede elegir ``box``, ``links``, ``keypoints`` y ``none`` (el valor predeterminado es ``links,keypoints``)\r\n",
        "\r\n",
        "```\r\n",
        "# C++\r\n",
        "$ ./posenet --overlay=box images/humans_0.jpg images/test/humans_0.jpg          # Visualize box\r\n",
        "$ ./posenet --overlay=links images/humans_0.jpg images/test/humans_0.jpg        # Visualize links\r\n",
        "$ ./posenet --overlay=keypoints images/humans_0.jpg images/test/humans_0.jpg    # Visualize keypoints\r\n",
        "$ ./posenet --overlay=none images/humans_0.jpg images/test/humans_0.jpg         # Visualize none\r\n",
        "\r\n",
        "# Python\r\n",
        "$ ./posenet.py --overlay=box images/humans_0.jpg images/test/humans_0.jpg          # Visualize box\r\n",
        "$ ./posenet.py --overlay=links images/humans_0.jpg images/test/humans_0.jpg        # Visualize links\r\n",
        "$ ./posenet.py --overlay=keypoints images/humans_0.jpg images/test/humans_0.jpg    # Visualize keypoints\r\n",
        "$ ./posenet.py --overlay=none images/humans_0.jpg images/test/humans_0.jpg         # Visualize none\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tamaño de los puntos"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede cambiar el tamaño de los puntos mediante el flag `--keypoint-scale` (el valor predeterminado es 0.0052). Cuanto más pequeño el valor, más pequeño es el punto\r\n",
        "\r\n",
        "```\r\n",
        "# C++\r\n",
        "$ ./posenet --keypoint-scale=0.0005 images/humans_1.jpg images/test/humans_1.jpg\r\n",
        "$ ./posenet --keypoint-scale=0.0090 images/humans_2.jpg images/test/humans_2.jpg\r\n",
        "\r\n",
        "# Python\r\n",
        "$ ./posenet.py --keypoint-scale=0.0005 images/humans_1.jpg images/test/humans_1.jpg\r\n",
        "$ ./posenet.py --keypoint-scale=0.0090 images/humans_2.jpg images/test/humans_2.jpg\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tamaño de las lineas"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede cambiar el tamaño de las lineas mediante el flag `--link-scale` (el valor predeterminado es 0.0013). Cuanto más pequeño el valor, más pequeña es la linea\r\n",
        "\r\n",
        "```\r\n",
        "# C++\r\n",
        "$ ./posenet --link-scale=0.0001 images/humans_1.jpg images/test/humans_1.jpg\r\n",
        "$ ./posenet --link-scale=0.0090 images/humans_2.jpg images/test/humans_2.jpg\r\n",
        "\r\n",
        "# Python\r\n",
        "$ ./posenet.py --link-scale=0.0001 images/humans_1.jpg images/test/humans_1.jpg\r\n",
        "$ ./posenet.py --link-scale=0.0090 images/humans_2.jpg images/test/humans_2.jpg\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Threshold"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede cambiar el humbral de detección mediante el flag `--threshold` (el valor predeterminado es 0.15). Cuanto más pequeño el valor, más detecta\r\n",
        "\r\n",
        "```\r\n",
        "# C++\r\n",
        "$ ./posenet --threshold=0.01 images/humans_4.jpg images/test/humans_4.jpg\r\n",
        "$ ./posenet --threshold=0.90 images/humans_4.jpg images/test/humans_4.jpg\r\n",
        "\r\n",
        "# Python\r\n",
        "$ ./posenet.py --threshold=0.01 images/humans_4.jpg images/test/humans_4.jpg\r\n",
        "$ ./posenet.py --threshold=0.90 images/humans_4.jpg images/test/humans_4.jpg\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Segmentación de vídeos"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si se quiere procesar un videdo solo hay que indicarlo en la entrada\r\n",
        "\r\n",
        "Para ello ejecutamos el docker montando la carpeta del SDK de VisionWorks\r\n",
        "\r\n",
        "```\r\n",
        "$ docker/run.sh --volume /usr/share/visionworks/sources/data:/videos\r\n",
        "```\r\n",
        "\r\n",
        "Y ya lo podemos procesar\r\n",
        "\r\n",
        "```\r\n",
        "# C++\r\n",
        "$ ./posenet /videos/pedestrians.mp4 images/test/pedestrians_pose.mp4\r\n",
        "\r\n",
        "# Python\r\n",
        "$ ./posenet.py /videos/pedestrians.mp4 images/test/pedestrians_pose.mp4\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crear un programa de clasificación en Python"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como vamos a crear un programa, lo primero que tenemos que hacer es crear una carpeta en el Host donde guardaremos el programa\r\n",
        "\r\n",
        "```\r\n",
        "$ cd ~/\r\n",
        "$ mkdir my-pose-python\r\n",
        "$ cd my-pose-python\r\n",
        "$ touch my-pose.py\r\n",
        "$ chmod +x my-pose.py\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación lo que hay que hacer es lanzar el Docker con una carpeta del Host compartida, para que así cuando se cierre el Docker no se borre el programa, para ello lanzamos el Docker con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ docker/run.sh --volume ~/my-pose-python:/my-pose-python   # mounted inside the container to /my-pose-python\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez dentro del Docker ir a la carpeta con los siguientes comandos\r\n",
        "\r\n",
        "```\r\n",
        "$ cd ../\r\n",
        "$ cd my-pose-python\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Editar el archivo .py con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ nano my-pose.py\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para crear un programa como el precompilado escribimos el siguiente código\r\n",
        "\r\n",
        "```Python\r\n",
        "import jetson.inference\r\n",
        "import jetson.utils\r\n",
        "\r\n",
        "import argparse\r\n",
        "import sys\r\n",
        "\r\n",
        "# parse the command line\r\n",
        "parser = argparse.ArgumentParser(description=\"Run pose estimation DNN on a video/image stream.\", \r\n",
        "                                 formatter_class=argparse.RawTextHelpFormatter, epilog=jetson.inference.poseNet.Usage() +\r\n",
        "                                 jetson.utils.videoSource.Usage() + jetson.utils.videoOutput.Usage() + jetson.utils.logUsage())\r\n",
        "\r\n",
        "parser.add_argument(\"input_URI\", type=str, default=\"\", nargs='?', help=\"URI of the input stream\")\r\n",
        "parser.add_argument(\"output_URI\", type=str, default=\"\", nargs='?', help=\"URI of the output stream\")\r\n",
        "parser.add_argument(\"--network\", type=str, default=\"resnet18-body\", help=\"pre-trained model to load (see below for options)\")\r\n",
        "parser.add_argument(\"--overlay\", type=str, default=\"links,keypoints\", help=\"pose overlay flags (e.g. --overlay=links,keypoints)\\nvalid combinations are:  'links', 'keypoints', 'boxes', 'none'\")\r\n",
        "parser.add_argument(\"--threshold\", type=float, default=0.15, help=\"minimum detection threshold to use\") \r\n",
        "\r\n",
        "try:\r\n",
        "\topt = parser.parse_known_args()[0]\r\n",
        "except:\r\n",
        "\tprint(\"\")\r\n",
        "\tparser.print_help()\r\n",
        "\tsys.exit(0)\r\n",
        "\r\n",
        "# load the pose estimation model\r\n",
        "net = jetson.inference.poseNet(opt.network, sys.argv, opt.threshold)\r\n",
        "\r\n",
        "# create video sources & outputs\r\n",
        "input = jetson.utils.videoSource(opt.input_URI, argv=sys.argv)\r\n",
        "output = jetson.utils.videoOutput(opt.output_URI, argv=sys.argv)\r\n",
        "\r\n",
        "# process frames until the user exits\r\n",
        "while True:\r\n",
        "    # capture the next image\r\n",
        "    img = input.Capture()\r\n",
        "\r\n",
        "    # perform pose estimation (with overlay)\r\n",
        "    poses = net.Process(img, overlay=opt.overlay)\r\n",
        "\r\n",
        "    # print the pose results\r\n",
        "    print(\"detected {:d} objects in image\".format(len(poses)))\r\n",
        "\r\n",
        "    for pose in poses:\r\n",
        "        print(pose)\r\n",
        "        print(pose.Keypoints)\r\n",
        "        print('Links', pose.Links)\r\n",
        "\r\n",
        "    # render the image\r\n",
        "    output.Render(img)\r\n",
        "\r\n",
        "    # update the title bar\r\n",
        "    output.SetStatus(\"{:s} | Network {:.0f} FPS\".format(opt.network, net.GetNetworkFPS()))\r\n",
        "\r\n",
        "    # print out performance info\r\n",
        "    net.PrintProfilerTimes()\r\n",
        "\r\n",
        "    # exit on input/output EOS\r\n",
        "    if not input.IsStreaming() or not output.IsStreaming():\r\n",
        "        break\r\n",
        "\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecutar el programa con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ python3 my-pose.py /dev/video0\r\n",
        "```\r\n",
        "\r\n",
        "En este caso abrirá la webcam, se pueden introducir las mismas variables que con el programa precompilado"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crear un programa ded clasificación en C++"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como vamos a crear un programa, lo primero que tenemos que hacer es crear una carpeta en el Host donde guardaremos el programa\r\n",
        "\r\n",
        "```\r\n",
        "$ cd ~/\r\n",
        "$ mkdir my-pose-cpp\r\n",
        "$ cd my-pose-cpp\r\n",
        "$ touch my-pose.cpp\r\n",
        "$ chmod +x my-pose.cpp\r\n",
        "$ touch CMakeLists.txt\r\n",
        "$ chmod +x CMakeLists.txt\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación lo que hay que hacer es lanzar el Docker con una carpeta del Host compartida, para que así cuando se cierre el Docker no se borre el programa, para ello lanzamos el Docker con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ docker/run.sh --volume ~/my-pose-cpp:/my-pose-cpp   # mounted inside the container to /my-pose-cpp\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez dentro del Docker ir a la carpeta con los siguientes comandos\r\n",
        "\r\n",
        "```\r\n",
        "$ cd ../\r\n",
        "$ cd my-pose-cpp\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Editar el archivo.cpp con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ nano my-pose.cpp\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para crear un programa como el precompilado escribimos el siguiente código\r\n",
        "\r\n",
        "```C++\r\n",
        "#include <jetson-utils/videoSource.h>\r\n",
        "#include <jetson-utils/videoOutput.h>\r\n",
        "\r\n",
        "#include <jetson-utils/cudaFont.h>\r\n",
        "#include <jetson-inference/poseNet.h>\r\n",
        "\r\n",
        "#include <signal.h>\r\n",
        "\r\n",
        "\r\n",
        "bool signal_recieved = false;\r\n",
        "\r\n",
        "void sig_handler(int signo)\r\n",
        "{\r\n",
        "\tif( signo == SIGINT )\r\n",
        "\t{\r\n",
        "\t\tLogVerbose(\"received SIGINT\\n\");\r\n",
        "\t\tsignal_recieved = true;\r\n",
        "\t}\r\n",
        "}\r\n",
        "\r\n",
        "int usage()\r\n",
        "{\r\n",
        "\tprintf(\"usage: posenet [--help] [--network=NETWORK] ...\\n\");\r\n",
        "\tprintf(\"                input_URI [output_URI]\\n\\n\");\r\n",
        "\tprintf(\"Run pose estimation DNN on a video/image stream.\\n\");\r\n",
        "\tprintf(\"See below for additional arguments that may not be shown above.\\n\\n\");\t\r\n",
        "\tprintf(\"positional arguments:\\n\");\r\n",
        "\tprintf(\"    input_URI       resource URI of input stream  (see videoSource below)\\n\");\r\n",
        "\tprintf(\"    output_URI      resource URI of output stream (see videoOutput below)\\n\\n\");\r\n",
        "\r\n",
        "\tprintf(\"%s\", poseNet::Usage());\r\n",
        "\tprintf(\"%s\", videoSource::Usage());\r\n",
        "\tprintf(\"%s\", videoOutput::Usage());\r\n",
        "\tprintf(\"%s\", Log::Usage());\r\n",
        "\r\n",
        "\treturn 0;\r\n",
        "}\r\n",
        "\r\n",
        "int main( int argc, char** argv )\r\n",
        "{\r\n",
        "\t/*\r\n",
        "\t * parse command line\r\n",
        "\t */\r\n",
        "\tcommandLine cmdLine(argc, argv);\r\n",
        "\r\n",
        "\tif( cmdLine.GetFlag(\"help\") )\r\n",
        "\t\treturn usage();\r\n",
        "\r\n",
        "\r\n",
        "\t/*\r\n",
        "\t * attach signal handler\r\n",
        "\t */\r\n",
        "\tif( signal(SIGINT, sig_handler) == SIG_ERR )\r\n",
        "\t\tLogError(\"can't catch SIGINT\\n\");\r\n",
        "\r\n",
        "\r\n",
        "\t/*\r\n",
        "\t * create input stream\r\n",
        "\t */\r\n",
        "\tvideoSource* input = videoSource::Create(cmdLine, ARG_POSITION(0));\r\n",
        "\r\n",
        "\tif( !input )\r\n",
        "\t{\r\n",
        "\t\tLogError(\"posenet: failed to create input stream\\n\");\r\n",
        "\t\treturn 0;\r\n",
        "\t}\r\n",
        "\r\n",
        "\r\n",
        "\t/*\r\n",
        "\t * create output stream\r\n",
        "\t */\r\n",
        "\tvideoOutput* output = videoOutput::Create(cmdLine, ARG_POSITION(1));\r\n",
        "\t\r\n",
        "\tif( !output )\r\n",
        "\t\tLogError(\"posenet: failed to create output stream\\n\");\t\r\n",
        "\t\r\n",
        "\r\n",
        "\t/*\r\n",
        "\t * create recognition network\r\n",
        "\t */\r\n",
        "\tposeNet* net = poseNet::Create(cmdLine);\r\n",
        "\t\r\n",
        "\tif( !net )\r\n",
        "\t{\r\n",
        "\t\tLogError(\"posenet: failed to initialize poseNet\\n\");\r\n",
        "\t\treturn 0;\r\n",
        "\t}\r\n",
        "\r\n",
        "\t// parse overlay flags\r\n",
        "\tconst uint32_t overlayFlags = poseNet::OverlayFlagsFromStr(cmdLine.GetString(\"overlay\", \"links,keypoints\"));\r\n",
        "\t\r\n",
        "\t\r\n",
        "\t/*\r\n",
        "\t * processing loop\r\n",
        "\t */\r\n",
        "\twhile( !signal_recieved )\r\n",
        "\t{\r\n",
        "\t\t// capture next image image\r\n",
        "\t\tuchar3* image = NULL;\r\n",
        "\r\n",
        "\t\tif( !input->Capture(&image, 1000) )\r\n",
        "\t\t{\r\n",
        "\t\t\t// check for EOS\r\n",
        "\t\t\tif( !input->IsStreaming() )\r\n",
        "\t\t\t\tbreak;\r\n",
        "\r\n",
        "\t\t\tLogError(\"posenet: failed to capture next frame\\n\");\r\n",
        "\t\t\tcontinue;\r\n",
        "\t\t}\r\n",
        "\r\n",
        "\t\t// run pose estimation\r\n",
        "\t\tstd::vector<poseNet::ObjectPose> poses;\r\n",
        "\t\t\r\n",
        "\t\tif( !net->Process(image, input->GetWidth(), input->GetHeight(), poses, overlayFlags) )\r\n",
        "\t\t{\r\n",
        "\t\t\tLogError(\"posenet: failed to process frame\\n\");\r\n",
        "\t\t\tcontinue;\r\n",
        "\t\t}\r\n",
        "\t\t\r\n",
        "\t\tLogInfo(\"posenet: detected %zu %s(s)\\n\", poses.size(), net->GetCategory());\r\n",
        "\t\t\r\n",
        "\t\t// render outputs\r\n",
        "\t\tif( output != NULL )\r\n",
        "\t\t{\r\n",
        "\t\t\toutput->Render(image, input->GetWidth(), input->GetHeight());\r\n",
        "\r\n",
        "\t\t\t// update status bar\r\n",
        "\t\t\tchar str[256];\r\n",
        "\t\t\tsprintf(str, \"TensorRT %i.%i.%i | %s | Network %.0f FPS\", NV_TENSORRT_MAJOR, NV_TENSORRT_MINOR, NV_TENSORRT_PATCH, precisionTypeToStr(net->GetPrecision()), net->GetNetworkFPS());\r\n",
        "\t\t\toutput->SetStatus(str);\t\r\n",
        "\r\n",
        "\t\t\t// check if the user quit\r\n",
        "\t\t\tif( !output->IsStreaming() )\r\n",
        "\t\t\t\tsignal_recieved = true;\r\n",
        "\t\t}\r\n",
        "\r\n",
        "\t\t// print out timing info\r\n",
        "\t\tnet->PrintProfilerTimes();\r\n",
        "\t}\r\n",
        "\t\r\n",
        "\t\r\n",
        "\t/*\r\n",
        "\t * destroy resources\r\n",
        "\t */\r\n",
        "\tLogVerbose(\"posenet: shutting down...\\n\");\r\n",
        "\t\r\n",
        "\tSAFE_DELETE(input);\r\n",
        "\tSAFE_DELETE(output);\r\n",
        "\tSAFE_DELETE(net);\r\n",
        "\t\r\n",
        "\tLogVerbose(\"posenet: shutdown complete.\\n\");\r\n",
        "\treturn 0;\r\n",
        "}\r\n",
        "\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Editar el CMakeList.txt con lo siguiente\r\n",
        "\r\n",
        "```\r\n",
        "# require CMake 2.8 or greater\r\n",
        "cmake_minimum_required(VERSION 2.8)\r\n",
        "\r\n",
        "# declare my-pose project\r\n",
        "project(my-pose)\r\n",
        "\r\n",
        "# import jetson-inference and jetson-utils packages.\r\n",
        "# note that if you didn't do \"sudo make install\"\r\n",
        "# while building jetson-inference, this will error.\r\n",
        "find_package(jetson-utils)\r\n",
        "find_package(jetson-inference)\r\n",
        "\r\n",
        "# CUDA and Qt4 are required\r\n",
        "find_package(CUDA)\r\n",
        "find_package(Qt4)\r\n",
        "\r\n",
        "# setup Qt4 for build\r\n",
        "include(${QT_USE_FILE})\r\n",
        "add_definitions(${QT_DEFINITIONS})\r\n",
        "\r\n",
        "# compile the my-pose program\r\n",
        "cuda_add_executable(my-pose my-pose.cpp)\r\n",
        "\r\n",
        "# link my-pose to jetson-inference library\r\n",
        "target_link_libraries(my-pose jetson-inference)\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilar el código con los siguientes comandos\r\n",
        "\r\n",
        "```\r\n",
        "$ cmake .\r\n",
        "$ make\r\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecutar el programa con el siguiente comando\r\n",
        "\r\n",
        "```\r\n",
        "$ ./my-pose /dev/video0\r\n",
        "```\r\n",
        "\r\n",
        "En este caso abrirá la webcam, se pueden introducir las mismas variables que con el programa precompilado"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.11 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "d1c24abb23a313e1f9ae042292cd8e6e3c60c5818227ced3d46e3df2c65171ef"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}