{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Detección de objetos con DetectNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La lista de objetos que se pueden detectar mediante las redes preentrenadas se encuentra en este [enlace](https://github.com/dusty-nv/jetson-inference/blob/master/data/networks/ssd_coco_labels.txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Uso de los programas precompilados de la Jetson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aquí se pueden encontrar los códigos de los programas precompilados:\n",
        " * [C++](https://github.com/dusty-nv/jetson-inference/blob/master/examples/detectnet/detectnet.cpp)\n",
        " * [Python](https://github.com/dusty-nv/jetson-inference/blob/master/python/examples/detectnet.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ir a la carpeta con los programas precompilados con el siguiente comando\n",
        "\n",
        "```\n",
        "$ cd jetson-inference/build/aarch64/bin\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación, detectemos objetos en una imagen de ejemplo con el programap precompilado detectNet, tanto en C++ como en Python. Si está utilizando el contenedor Docker, es recomendable guardar la imagen de salida en el directorio images/test. Estas imágenes se podrán ver fácilmente desde su dispositivo host en el directorio jetson-inference/data/images/test.\n",
        "\n",
        "```\n",
        "# C++\n",
        "$ ./detectnet images/peds_0.jpg images/test/peds_0.jpg     # (default network is SSD-Mobilenet-v2)\n",
        "\n",
        "# Python\n",
        "$ ./detectnet.py images/peds_0.jpg images/test/peds_0.jpg  # (default network is SSD-Mobilenet-v2)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si queremos detectar varias imágenes\n",
        "\n",
        "```\n",
        "# C++\n",
        "$ ./detectnet \"images/peds_*.jpg\" \"images/test/peds_%i.jpg\"     # (default network is SSD-Mobilenet-v2)\n",
        "\n",
        "# Python\n",
        "$ ./detectnet.py \"images/peds_*.jpg\" \"images/test/peds_%i.jpg\"  # (default network is SSD-Mobilenet-v2)\n",
        "```\n",
        "\n",
        " > **nota**: cuando se usen asteriscos, hay que escribirlos siempre entre comillas (\"*.jpg\"). De lo contrario, el sistema operativo expandirá automáticamente la secuencia y modificará el orden de los argumentos en la línea de comandos, lo que puede resultar en que una de las imágenes de entrada sea sobrescrita por la salida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si queremos usar otras redes (por defecto se usa GoogleNet) hay que usar el flag ```--network```\n",
        "\n",
        "```\n",
        "# C++\n",
        "$ ./detectnet --network=coco-airplane \"images/airplane_*.jpg\" \"images/test/airplane_%i.jpg\"\n",
        "\n",
        "# Python\n",
        "$ ./detectnet.py --network=coco-airplane \"images/airplane_*.jpg\" \"images/test/airplane_%i.jpg\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las redes que podemos usar para localización son:\n",
        "|Network|argumento CLI|Network Type enum|Object classes|\n",
        "|------|--------------|-----------------|--------------|\n",
        "|SSD-Mobilenet-v1|`ssd-mobilenet-v1`|``SSD_MOBILENET_V1``|91 ([COCO classes](https://github.com/dusty-nv/jetson-inference/blob/master/data/networks/ssd_coco_labels.txt))|\n",
        "|SSD-Mobilenet-v2|``ssd-mobilenet-v2``|``SSD_MOBILENET_V2``|91 ([COCO classes](https://github.com/dusty-nv/jetson-inference/blob/master/data/networks/ssd_coco_labels.txt))|\n",
        "|SSD-Inception-v2|``ssd-inception-v2``|``SSD_INCEPTION_V2``|91 ([COCO classes](https://github.com/dusty-nv/jetson-inference/blob/master/data/networks/ssd_coco_labels.txt))|\n",
        "|DetectNet-COCO-Dog|``coco-dog``|``COCO_DOG``|dogs|\n",
        "|DetectNet-COCO-Bottle|``coco-bottle``|``COCO_BOTTLE``|bottles|\n",
        "|DetectNet-COCO-Chair|``coco-chair``|``COCO_CHAIR``|chairs|\n",
        "|DetectNet-COCO-Airplane|``coco-airplane``|``COCO_AIRPLANE``|airplanes|\n",
        "|ped-100|``pednet``|``PEDNET``|pedestrians|\n",
        "|multiped-500|``multiped``|``PEDNET_MULTI``|pedestrians, luggage|\n",
        "|facenet-120|``facenet``|``FACENET``|faces|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se puede elegir la información que sale en la imagen mediante el flag `--overlay`. Se puede elegir que aparezca una caja delimitadora (`box`), la etiqueta (`label`), la confianza (`conf`) o nada (`none`). Por defecto la configuración es `--overlay=box,labels,conf`.\n",
        "```\n",
        "# C++\n",
        "$ ./detectnet --overlay=box,labels images/cat_0.jpg images/test/cat_0.jpg     # Only box and label\n",
        "\n",
        "# Python\n",
        "$ ./detectnet.py --overlay=box,labels images/cat_0.jpg images/test/cat_0.jpg  # Only box and label\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se puede elegir la transparencia de la caja mediante el flag `--alpha`, cuanto más pequeño es el valor más transparente es la caja. Por defecto `--alpha=120`\n",
        "\n",
        "```\n",
        "# C++\n",
        "$ ./detectnet --alpha=50 images/cat_0.jpg images/test/cat_0.jpg      # Alpha 50\n",
        "$ ./detectnet --alpha=200 images/cat_0.jpg images/test/cat_0.jpg     # Alpha 200\n",
        "\n",
        "# Python\n",
        "$ ./detectnet.py --alpha=50 images/cat_0.jpg images/test/cat_0.jpg   # Alpha 50\n",
        "$ ./detectnet.py --alpha=200 images/cat_0.jpg images/test/cat_0.jpg  # Alpha 200\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se puede determinar el valor humbral para que la red considere un objeto mediante el flag `--threshold`. Por defecto `--threshold=0.5`\n",
        "\n",
        "```\n",
        "# C++\n",
        "$ ./detectnet --threshold=0.2 images/peds_3.jpg images/test/peds_3.jpg     # threshold 0.2\n",
        "$ ./detectnet --threshold=0.8 images/peds_3.jpg images/test/peds_3.jpg     # threshold 0.8\n",
        "\n",
        "# Python\n",
        "$ ./detectnet.py --threshold=0.2 images/peds_3.jpg images/test/peds_3.jpg  # threshold 0.2\n",
        "$ ./detectnet.py --threshold=0.8 images/peds_3.jpg images/test/peds_3.jpg  # threshold 0.8\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si se quiere procesar un videdo solo hay que indicarlo en la entrada\n",
        "\n",
        "Para ello ejecutamos el docker montando la carpeta del SDK de VisionWorks\n",
        "\n",
        "```\n",
        "$ docker/run.sh --volume /usr/share/visionworks/sources/data:/videos\n",
        "```\n",
        "\n",
        "Y ya lo podemos procesar\n",
        "\n",
        "```\n",
        "# C++\n",
        "$ ./detectnet --threshold=0.35 /videos/pedestrians.mp4 images/test/pedestrians_ssd.mp4\n",
        "\n",
        "# Python\n",
        "$ ./detectnet.py --threshold=0.35 /videos/pedestrians.mp4 images/test/pedestrians_ssd.mp4\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Crear un programa de clasificación en Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como vamos a crear un programa, lo primero que tenemos que hacer es crear una carpeta en el Host donde guardaremos el programa\n",
        "\n",
        "```\n",
        "$ cd ~/\n",
        "$ mkdir my-detection-python\n",
        "$ cd my-detection-python\n",
        "$ touch my-detection.py\n",
        "$ chmod +x my-detection.py\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nos descargamos unas imágenes de osos para probar\n",
        "\n",
        "```\n",
        "$ wget https://github.com/dusty-nv/jetson-inference/raw/master/data/images/black_bear.jpg\n",
        "$ wget https://github.com/dusty-nv/jetson-inference/raw/master/data/images/brown_bear.jpg\n",
        "$ wget https://github.com/dusty-nv/jetson-inference/raw/master/data/images/polar_bear.jpg\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación lo que hay que hacer es lanzar el Docker con una carpeta del Host compartida, para que así cuando se cierre el Docker no se borre el programa, para ello lanzamos el Docker con el siguiente comando\n",
        "\n",
        "```\n",
        "$ docker/run.sh --volume ~/my-detection-python:/my-detection-python   # mounted inside the container to /my-detection-python\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Una vez dentro del Docker ir a la carpeta con los siguientes comandos\n",
        "\n",
        "```\n",
        "$ cd ../\n",
        "$ cd my-detection-python\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Editar el archivo .py con el siguiente comando\n",
        "\n",
        "```\n",
        "$ nano my-detection.py\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para crear un programa como el precompilado escribimos el siguiente código\n",
        "\n",
        "```Python\n",
        "import jetson.inference\n",
        "import jetson.utils\n",
        "\n",
        "import argparse\n",
        "import sys\n",
        "\n",
        "# parse the command line\n",
        "parser = argparse.ArgumentParser(description=\"Locate objects in a live camera stream using an object detection DNN.\", \n",
        "                                 formatter_class=argparse.RawTextHelpFormatter, epilog=jetson.inference.detectNet.Usage() +\n",
        "                                 jetson.utils.videoSource.Usage() + jetson.utils.videoOutput.Usage() + jetson.utils.logUsage())\n",
        "\n",
        "parser.add_argument(\"input_URI\", type=str, default=\"\", nargs='?', help=\"URI of the input stream\")\n",
        "parser.add_argument(\"output_URI\", type=str, default=\"\", nargs='?', help=\"URI of the output stream\")\n",
        "parser.add_argument(\"--network\", type=str, default=\"ssd-mobilenet-v2\", help=\"pre-trained model to load (see below for options)\")\n",
        "parser.add_argument(\"--overlay\", type=str, default=\"box,labels,conf\", help=\"detection overlay flags (e.g. --overlay=box,labels,conf)\\nvalid combinations are:  'box', 'labels', 'conf', 'none'\")\n",
        "parser.add_argument(\"--threshold\", type=float, default=0.5, help=\"minimum detection threshold to use\") \n",
        "\n",
        "is_headless = [\"--headless\"] if sys.argv[0].find('console.py') != -1 else [\"\"]\n",
        "\n",
        "try:\n",
        "\topt = parser.parse_known_args()[0]\n",
        "except:\n",
        "\tprint(\"\")\n",
        "\tparser.print_help()\n",
        "\tsys.exit(0)\n",
        "\n",
        "# create video output object \n",
        "output = jetson.utils.videoOutput(opt.output_URI, argv=sys.argv+is_headless)\n",
        "\t\n",
        "# load the object detection network\n",
        "net = jetson.inference.detectNet(opt.network, sys.argv, opt.threshold)\n",
        "\n",
        "# create video sources\n",
        "input = jetson.utils.videoSource(opt.input_URI, argv=sys.argv)\n",
        "\n",
        "\n",
        "# process frames until the user exits\n",
        "while True:\n",
        "\t# capture the next image\n",
        "\timg = input.Capture()\n",
        "\n",
        "\t# detect objects in the image (with overlay)\n",
        "\tdetections = net.Detect(img, overlay=opt.overlay)\n",
        "\n",
        "\t# print the detections\n",
        "\tprint(\"detected {:d} objects in image\".format(len(detections)))\n",
        "\n",
        "\tfor detection in detections:\n",
        "\t\tprint(f\"\\t{detection}\")\n",
        "\n",
        "\t\t# find the object description\n",
        "\t\tclass_description = net.GetClassDesc(detection.ClassID)\n",
        "\t\tprint(f\"\\t clase {detection.ClassID}: {class_description}\")\n",
        "\n",
        "\t# render the image\n",
        "\toutput.Render(img)\n",
        "\n",
        "\t# update the title bar\n",
        "\toutput.SetStatus(\"{:s} | Network {:.0f} FPS\".format(opt.network, net.GetNetworkFPS()))\n",
        "\n",
        "\t# print out performance info\n",
        "\tnet.PrintProfilerTimes()\n",
        "\n",
        "\t# exit on input/output EOS\n",
        "\tif not input.IsStreaming() or not output.IsStreaming():\n",
        "\t\tbreak\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ejecutar el programa con el siguiente comando\n",
        "\n",
        "```\n",
        "$ python3 my-detection.py /dev/video0\n",
        "```\n",
        "\n",
        "En este caso abrirá la webcam, se pueden introducir las mismas variables que con el programa precompilado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Crear un programa ded clasificación en C++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como vamos a crear un programa, lo primero que tenemos que hacer es crear una carpeta en el Host donde guardaremos el programa\n",
        "\n",
        "```\n",
        "$ cd ~/\n",
        "$ mkdir my-detection-cpp\n",
        "$ cd my-detection-cpp\n",
        "$ touch my-detection.cpp\n",
        "$ chmod +x my-detection.cpp\n",
        "$ touch CMakeLists.txt\n",
        "$ chmod +x CMakeLists.txt\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nos descargamos unas imágenes de osos para probar\n",
        "\n",
        "```\n",
        "$ wget https://github.com/dusty-nv/jetson-inference/raw/master/data/images/black_bear.jpg\n",
        "$ wget https://github.com/dusty-nv/jetson-inference/raw/master/data/images/brown_bear.jpg\n",
        "$ wget https://github.com/dusty-nv/jetson-inference/raw/master/data/images/polar_bear.jpg\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación lo que hay que hacer es lanzar el Docker con una carpeta del Host compartida, para que así cuando se cierre el Docker no se borre el programa, para ello lanzamos el Docker con el siguiente comando\n",
        "\n",
        "```\n",
        "$ docker/run.sh --volume ~/my-detection-cpp:/my-detection-cpp   # mounted inside the container to /my-detection-cpp\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Una vez dentro del Docker ir a la carpeta con los siguientes comandos\n",
        "\n",
        "```\n",
        "$ cd ../\n",
        "$ cd my-detection-cpp\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Editar el archivo .py con el siguiente comando\n",
        "\n",
        "```\n",
        "$ nano my-detection.cpp\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para crear un programa como el precompilado escribimos el siguiente código\n",
        "\n",
        "```C++\n",
        "#include <jetson-utils/videoSource.h>\n",
        "#include <jetson-utils/videoOutput.h>\n",
        "\n",
        "#include <jetson-utils/cudaFont.h>\n",
        "#include <jetson-inference/detectNet.h>\n",
        "\n",
        "#include <signal.h>\n",
        "\n",
        "\n",
        "#ifdef HEADLESS\n",
        "\t#define IS_HEADLESS() \"headless\"\t// run without display\n",
        "#else\n",
        "\t#define IS_HEADLESS() (const char*)NULL\n",
        "#endif\n",
        "\n",
        "\n",
        "bool signal_recieved = false;\n",
        "\n",
        "void sig_handler(int signo)\n",
        "{\n",
        "\tif( signo == SIGINT )\n",
        "\t{\n",
        "\t\tLogVerbose(\"received SIGINT\\n\");\n",
        "\t\tsignal_recieved = true;\n",
        "\t}\n",
        "}\n",
        "\n",
        "int usage()\n",
        "{\n",
        "\tprintf(\"usage: detectnet [--help] [--network=NETWORK] [--threshold=THRESHOLD] ...\\n\");\n",
        "\tprintf(\"                 input_URI [output_URI]\\n\\n\");\n",
        "\tprintf(\"Locate objects in a video/image stream using an object detection DNN.\\n\");\n",
        "\tprintf(\"See below for additional arguments that may not be shown above.\\n\\n\");\n",
        "\tprintf(\"positional arguments:\\n\");\n",
        "\tprintf(\"    input_URI       resource URI of input stream  (see videoSource below)\\n\");\n",
        "\tprintf(\"    output_URI      resource URI of output stream (see videoOutput below)\\n\\n\");\n",
        "\n",
        "\tprintf(\"%s\", detectNet::Usage());\n",
        "\tprintf(\"%s\", videoSource::Usage());\n",
        "\tprintf(\"%s\", videoOutput::Usage());\n",
        "\tprintf(\"%s\", Log::Usage());\n",
        "\n",
        "\treturn 0;\n",
        "}\n",
        "\n",
        "int main( int argc, char** argv )\n",
        "{\n",
        "\t/*\n",
        "\t * parse command line\n",
        "\t */\n",
        "\tcommandLine cmdLine(argc, argv, IS_HEADLESS());\n",
        "\n",
        "\tif( cmdLine.GetFlag(\"help\") )\n",
        "\t\treturn usage();\n",
        "\n",
        "\n",
        "\t/*\n",
        "\t * attach signal handler\n",
        "\t */\n",
        "\tif( signal(SIGINT, sig_handler) == SIG_ERR )\n",
        "\t\tLogError(\"can't catch SIGINT\\n\");\n",
        "\n",
        "\n",
        "\t/*\n",
        "\t * create input stream\n",
        "\t */\n",
        "\tvideoSource* input = videoSource::Create(cmdLine, ARG_POSITION(0));\n",
        "\n",
        "\tif( !input )\n",
        "\t{\n",
        "\t\tLogError(\"detectnet:  failed to create input stream\\n\");\n",
        "\t\treturn 0;\n",
        "\t}\n",
        "\n",
        "\n",
        "\t/*\n",
        "\t * create output stream\n",
        "\t */\n",
        "\tvideoOutput* output = videoOutput::Create(cmdLine, ARG_POSITION(1));\n",
        "\t\n",
        "\tif( !output )\n",
        "\t\tLogError(\"detectnet:  failed to create output stream\\n\");\t\n",
        "\t\n",
        "\n",
        "\t/*\n",
        "\t * create detection network\n",
        "\t */\n",
        "\tdetectNet* net = detectNet::Create(cmdLine);\n",
        "\t\n",
        "\tif( !net )\n",
        "\t{\n",
        "\t\tLogError(\"detectnet:  failed to load detectNet model\\n\");\n",
        "\t\treturn 0;\n",
        "\t}\n",
        "\n",
        "\t// parse overlay flags\n",
        "\tconst uint32_t overlayFlags = detectNet::OverlayFlagsFromStr(cmdLine.GetString(\"overlay\", \"box,labels,conf\"));\n",
        "\t\n",
        "\n",
        "\t/*\n",
        "\t * processing loop\n",
        "\t */\n",
        "\twhile( !signal_recieved )\n",
        "\t{\n",
        "\t\t// capture next image image\n",
        "\t\tuchar3* image = NULL;\n",
        "\n",
        "\t\tif( !input->Capture(&image, 1000) )\n",
        "\t\t{\n",
        "\t\t\t// check for EOS\n",
        "\t\t\tif( !input->IsStreaming() )\n",
        "\t\t\t\tbreak; \n",
        "\n",
        "\t\t\tLogError(\"detectnet:  failed to capture video frame\\n\");\n",
        "\t\t\tcontinue;\n",
        "\t\t}\n",
        "\n",
        "\t\t// detect objects in the frame\n",
        "\t\tdetectNet::Detection* detections = NULL;\n",
        "\t\n",
        "\t\tconst int numDetections = net->Detect(image, input->GetWidth(), input->GetHeight(), &detections, overlayFlags);\n",
        "\t\t\n",
        "\t\tif( numDetections > 0 )\n",
        "\t\t{\n",
        "\t\t\tLogVerbose(\"%i objects detected\\n\", numDetections);\n",
        "\t\t\n",
        "\t\t\tfor( int n=0; n < numDetections; n++ )\n",
        "\t\t\t{\n",
        "\t\t\t\tLogVerbose(\"detected obj %i  class #%u (%s)  confidence=%f\\n\", n, detections[n].ClassID, net->GetClassDesc(detections[n].ClassID), detections[n].Confidence);\n",
        "\t\t\t\tLogVerbose(\"bounding box %i  (%f, %f)  (%f, %f)  w=%f  h=%f\\n\", n, detections[n].Left, detections[n].Top, detections[n].Right, detections[n].Bottom, detections[n].Width(), detections[n].Height()); \n",
        "\t\t\t}\n",
        "\t\t}\t\n",
        "\n",
        "\t\t// render outputs\n",
        "\t\tif( output != NULL )\n",
        "\t\t{\n",
        "\t\t\toutput->Render(image, input->GetWidth(), input->GetHeight());\n",
        "\n",
        "\t\t\t// update the status bar\n",
        "\t\t\tchar str[256];\n",
        "\t\t\tsprintf(str, \"TensorRT %i.%i.%i | %s | Network %.0f FPS\", NV_TENSORRT_MAJOR, NV_TENSORRT_MINOR, NV_TENSORRT_PATCH, precisionTypeToStr(net->GetPrecision()), net->GetNetworkFPS());\n",
        "\t\t\toutput->SetStatus(str);\n",
        "\n",
        "\t\t\t// check if the user quit\n",
        "\t\t\tif( !output->IsStreaming() )\n",
        "\t\t\t\tsignal_recieved = true;\n",
        "\t\t}\n",
        "\n",
        "\t\t// print out timing info\n",
        "\t\tnet->PrintProfilerTimes();\n",
        "\t}\n",
        "\t\n",
        "\n",
        "\t/*\n",
        "\t * destroy resources\n",
        "\t */\n",
        "\tLogVerbose(\"detectnet:  shutting down...\\n\");\n",
        "\t\n",
        "\tSAFE_DELETE(input);\n",
        "\tSAFE_DELETE(output);\n",
        "\tSAFE_DELETE(net);\n",
        "\n",
        "\tLogVerbose(\"detectnet:  shutdown complete.\\n\");\n",
        "\treturn 0;\n",
        "}\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Editar el CMakeList.txt con lo siguiente\n",
        "\n",
        "```\n",
        "# require CMake 2.8 or greater\n",
        "cmake_minimum_required(VERSION 2.8)\n",
        "\n",
        "# declare my-detection project\n",
        "project(my-detection)\n",
        "\n",
        "# import jetson-inference and jetson-utils packages.\n",
        "# note that if you didn't do \"sudo make install\"\n",
        "# while building jetson-inference, this will error.\n",
        "find_package(jetson-utils)\n",
        "find_package(jetson-inference)\n",
        "\n",
        "# CUDA and Qt4 are required\n",
        "find_package(CUDA)\n",
        "find_package(Qt4)\n",
        "\n",
        "# setup Qt4 for build\n",
        "include(${QT_USE_FILE})\n",
        "add_definitions(${QT_DEFINITIONS})\n",
        "\n",
        "# compile the my-detection program\n",
        "cuda_add_executable(my-detection my-detection.cpp)\n",
        "\n",
        "# link my-detection to jetson-inference library\n",
        "target_link_libraries(my-detection jetson-inference)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compilar el código con los siguientes comandos\n",
        "\n",
        "```\n",
        "$ cmake .\n",
        "$ make\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ejecutar el programa con el siguiente comando\n",
        "\n",
        "```\n",
        "$ ./my-detection /dev/video0\n",
        "```\n",
        "\n",
        "En este caso abrirá la webcam, se pueden introducir las mismas variables que con el programa precompilado"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "d1c24abb23a313e1f9ae042292cd8e6e3c60c5818227ced3d46e3df2c65171ef"
    },
    "kernelspec": {
      "display_name": "Python 3.8.11 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
