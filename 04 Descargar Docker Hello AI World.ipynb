{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Descargar Docker Hello AI World"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Descargar y ejecutar el Docker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Descargar el repositorio Hello AI Wolrd de Github mediante el siguiente comando\n",
        "\n",
        "```\n",
        " $ git clone --recursive https://github.com/dusty-nv/jetson-inference\n",
        "```\n",
        "\n",
        "la opción ```--recursive``` hace que se descarguen las librerías necesarias para el Docker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Una vez descargado el repositorio ejecutar el Docker mediante los siguientes comandos\n",
        "\n",
        "```\n",
        " $ cd jetson-inference\n",
        " $ docker/run.sh\n",
        "```\n",
        "\n",
        "El comando ```docker/run.sh``` extraerá automáticamente la etiqueta de contenedor correcta de DockerHub en función de la versión de JetPack-L4T instalada, y montará los directorios y dispositivos de datos adecuados para que pueda usar las cámaras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Volúmenes montados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como referencia, las siguientes rutas se montan automáticamente desde su dispositivo host en el contenedor:\n",
        "\n",
        " * ```jetson-inference/data``` (almacena los modelos de red, motores TensorRT serializados e imágenes de prueba)\n",
        " * ```jetson-inference/python/training/classification/data``` (almacena conjuntos de datos de entrenamiento de clasificación)\n",
        " * ```jetson-inference/python/training/classification/models``` (almacena modelos de clasificación entrenados por PyTorch)\n",
        " * ```jetson-inference/python/training/detection/ssd/data``` (almacena conjuntos de datos de entrenamiento de detección)\n",
        " * ```jetson-inference/python/training/detection/ssd/models``` (almacena modelos de detección entrenados por PyTorch)\n",
        "\n",
        "Estos volúmenes montados aseguran que los modelos y conjuntos de datos se almacenen fuera del contenedor y no se pierdan cuando se apaga el contenedor.\n",
        "\n",
        "Si se quiere montar otro directorio en el contenedor, se puede usar el argumento ```--volume HOST_DIR:MOUNT_DIR``` para el comando ```docker/run.sh```:\n",
        "\n",
        "```\n",
        " $ docker/run.sh --volume /my/host/path:/my/container/path    # these should be absolute paths\n",
        "```\n",
        "\n",
        "Para obtener más información, ejecutar ```docker/run.sh --help``` o consultar el texto de ayuda dentro de ```docker/run.sh```"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "d1c24abb23a313e1f9ae042292cd8e6e3c60c5818227ced3d46e3df2c65171ef"
    },
    "kernelspec": {
      "display_name": "Python 3.8.11 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
